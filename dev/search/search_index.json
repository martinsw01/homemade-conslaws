{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Conservation Laws","text":""},{"location":"#homemade-conslaws","title":"Homemade Conslaws","text":""},{"location":"#conservation-laws","title":"Conservation laws","text":"<p>Let \\(\\boldsymbol U\\) be a quantity defined on a domain \\(\\Omega \\subset \\R^n\\). For any subdomain \\(\\omega \\subset \\Omega\\), the temporal rate of change of \\(\\bm U\\) is equal to the amount of \\(\\bm U\\) created or destroyed and the flux going through the boundary \\(\\partial \\omega\\). It can be described mathematically by</p> \\[     \\dv{t} \\int_{\\omega} \\bm U \\dd \\x     = - \\int_{\\partial \\omega} \\bm F \\cdot \\bm \\nu \\dd \\s     + \\int_{\\omega} \\bm S \\dd \\x, \\] <p>where \\(\\bm F\\) is the flux and \\(\\bm S\\) is the source term. By the Gauss divergence theorem, we can rewrite this as</p> \\[     \\dv{t} \\int_{\\omega} \\bm U \\dd \\x     + \\int_{\\omega} \\div {\\bm F} \\dd \\x     = \\int_{\\omega} \\bm S \\dd \\x. \\] <p>Since this equation holds for all subdomains \\(\\omega \\subseteq \\Omega\\), we can write</p> \\[     \\bm U_t + \\div {\\bm F} = \\bm S \\quad \\text{ in } \\Omega \\times \\R_+ \\] <p>We call this equation a conservation law.</p>"},{"location":"final_report/","title":"Final Report","text":""},{"location":"theory/2nd_order_schemes/","title":"Second order schemes","text":""},{"location":"theory/2nd_order_schemes/#second-order-schemes","title":"Second order schemes","text":"\\[ \\begin{equation}     U_t + f(U)_x = 0 \\label{eq:conservation_law} \\end{equation} \\] <p>The schemes we have seen this far has slow convergence. We can improve the convergence by using higher order schemes.</p>"},{"location":"theory/2nd_order_schemes/#order-of-convergence","title":"Order of convergence","text":"<p>For a \\((2p+1)\\)-point scheme with update function \\(H\\) and \\(\\lambda \\equiv \\frac{\\Dt}{\\Dx}\\), we define the truncation error as usual as</p> \\[\\tau_j^n := U(x_j, t_{n+1}) - H(U_{j-p}^n, \\dots, U_{j+p}^n).\\] <p>We call it \\(q\\)-th order accurate if \\(q \\in \\N\\) is the largest integer such that</p> \\[\\tau_j^n = \\O(\\Dt^{q+1}) \\quad \\forall j, n.\\] <p>Lemma</p> <p>If \\(U \\in C^2\\) is the exact solution and \\(H\\) is a consistent, conservative \\(3\\)-point FVM, then the scheme is at least first order accurate.</p> Proof <p>Follows as usual from Taylor expansion.</p> <p>Example</p> <ul> <li>Both Lax-Friedrichs and Engquist-Osher use \\(C^2\\) numerical fluxes, and are thus first order accurate.</li> <li>Godunov is not, so we cannot use the lemma on it. However, one can still show that it is of first order accuracy.</li> </ul> <p>Kuznetsov [GR91] shows that monotone schemes has an order of convergence of at least \\(1/2\\):</p> \\[\\norm{U^{\\Dx} - U}_{L^1(\\R)} \\le C \\Dx^{1/2}.\\]"},{"location":"theory/2nd_order_schemes/#lax-wendroff-scheme","title":"Lax-Wendroff scheme","text":"<p>For weak solutions, one cannot use Taylor expansions to find the error. However, we can use it to design schemes that formally are better than first order. Let \\(U\\) be a smooth solution. Then, we have</p> \\[U_tt = \\qty(f'(U)U_x)_x.\\] <p>Inserting into the taylor expansion yields</p> \\[U(x_j, t_{n+1}) = U(x_j, t_n) + \\Dt U_t(x_j, t_n) + \\frac{\\Dt^2}{2} \\qty(f'(U)U_x)_x + \\O(\\Dt^3).\\] <p>The last two term are approximated by</p> \\[ \\begin{aligned}     f(U)_x &amp;= \\frac{f(U_{j+1}) - f(U_{j-1})}{2\\Dx} + \\O(\\Dx^3) \\\\     \\qty(f'(U)U_x)_x &amp;= \\frac{1}{\\Dx} \\qty(a_{j+1/2}^n \\frac{f(U_{j+1}^n) - f(U_j^n)}{\\Dx}     - a_{j-1/2}^n \\frac{f(U_j^n) - f(U_{j-1}^n)}{\\Dx}) + \\O(\\Dx^3), \\end{aligned} \\] <p>yielding the Lax-Wendroff scheme</p> \\[U_j^{n+1} = U_j^n - \\frac{\\Dt}{2\\Dx} \\Big(f(U_{j+1}^n) - f(U_{j-1}^n)\\Big) + \\frac{\\Dt^2}{2\\Dx^2} \\qty(a_{j+1/2}^n \\frac{f(U_{j+1}^n) - f(U_j^n)}{\\Dx} - a_{j-1/2}^n \\frac{f(U_j^n) - f(U_{j-1}^n)}{\\Dx}),\\] <p>where \\(a_{j+1/2}^n = f'\\qty(\\frac{U_j^n + U_{j+1}^n}{2})\\) is an approximation of \\(f'(U_{j+1/2}^n)\\). Alternatively, the numerical flux can be written as</p> \\[F_{j+1/2}^n = F^{\\text{LxW}}(U_j^n, U_{j+1}^n) = \\frac{f(U_j^n) + f(U_{j+1}^n)}{2} - a_{j+1/2}^n \\frac{\\Dt}{2\\Dx} \\qty(f(U_{j+1}^n) - f(U_j^n)).\\] <p>Numerical experiments show that the Lax-Wendroff scheme is second order accurate for smooth soluitons. Additionally, the discontinuities are sharper than for first order schemes. However, there are heavy oscillations near the shocks.</p>"},{"location":"theory/2nd_order_schemes/#rea-algorithm","title":"REA Algorithm","text":"<p>The derivation of the schemes presented in the last chapter went as follows:</p> <ul> <li>Reconstruction: Recreate \\(U(x,t^n)\\) from the cell averages \\(U_j^n\\). Prevoiusly, we used piecewise constant functions.</li> <li>Evolution: Solve the superposition of Riemann problems. This can be done approximately (LxF) or exactly (Godunov).</li> <li>Averaging: Average the solutions for each cell.</li> </ul> <p>The difference in many of the schemes presented is the evolution step. However, one can also increase the accuracy of the reconstruction step. One can for example use higher order interpolation.</p>"},{"location":"theory/2nd_order_schemes/#second-order-reconstruction","title":"Second order reconstruction","text":"<p>To determine the piecewise affine function, we need some requirements. One can show that the last two steps are conservative. It would be natural to require that the reconstruction too. For the interpolation function \\(p_j\\) in the cell \\(\\Cell_j\\), we thus require that</p> \\[p_j(x) = U_j^n + \\sigma_j^n(x - x_j).\\] <p>or instance, one can apply the standard slope approximation using central, backward, or forward difference methods. However, in the case of the linear advection equation with constant velocity, it can be demonstrated that using the forward difference approach leads to the Lax-Wendroff scheme. Oscillations also arise using the two other methods.</p>"},{"location":"theory/2nd_order_schemes/#source-of-oscillations","title":"Source of oscillations","text":"<p>The solutions of \\(\\eqref{eq:conservation_law}\\) are TVD. Thus, they are not oscillatory whenever the initial data is not. Finite volume methods should therefore not introduce oscillations. The averaging operator and suitable Riemann solvers respects TVD. Thus, the source must be the reconstruction step. Consider for example the cell averages</p> \\[U_j^n = \\begin{cases}     1 &amp; j \\le 0 \\\\     0 &amp; j &gt; 0. \\end{cases}\\] <p>It has total variation \\(\\norm{U^n}_{TV} = 1\\). Using the downwind reconstruction, we get</p> \\[\\sigma_j^n = \\begin{cases}     0 &amp; j \\neq 0 \\\\     -1/2 &amp; j = 0. \\end{cases}\\] <p>Thus, the reconstruction overshoots and reaches \\(3/2\\). The total variation is now \\(\\norm{p^n}_{TV} = 3/2\\). Similar arguments can be made for the other reconstruction methods. Therefore, we should require that the reconstruction operator is TVD: \\(\\norm{p}_{BV} \\le \\norm{U^{\\Dx}}_{BV}\\).</p>"},{"location":"theory/2nd_order_schemes/#minmod-limiter","title":"Minmod limiter","text":"<p>One such TVD reconstruction operator is the minmod limiter. The problem above at discontinuities occurs whenever the downwind and upwind slopes have opposite signs. One can therefore default to constant interpolation, that is, a slope of zero. This results in the minmod limiter:</p> \\[\\sigma_j^n = \\minmod\\qty(\\frac{U_{j+1}^n - U_j^n}{\\Dx}, \\frac{U_j^n - U_{j-1}^n}{\\Dx}),\\] <p>where</p> \\[\\minmod\\{a_k\\}_k = \\begin{cases}     \\sign(a_1) \\min_k\\abs{a_k}, &amp; \\sign(a_1) = \\dots = \\sign(a_n) \\\\     0, &amp; \\text{otherwise}. \\end{cases}\\]"},{"location":"theory/finite_volume_schemes/","title":"Finite volume schemes","text":"<p>We will now design efficient schemes for the conservation law</p> \\[ \\begin{equation}     U_t + f(U)_x = 0 \\label{eq:conservation_law} \\end{equation} \\] <p>We have already seen that finite difference schemes works poorly, even for linear transport:</p> <ul> <li>In this case, we had to \"upwind\" wind scheme, taking the derivative in the direction of  information propagation. This is not possible a-priori for non-linear equations like \\(\\eqref{eq:conservation_law}\\).</li> <li>It further requires smoothness and that \\(\\eqref{eq:conservation_law}\\) is satisfied pointwise. However, we are looking for entropy solutions, which may be discontinuous.</li> </ul>"},{"location":"theory/finite_volume_schemes/#finite-volume-schemes_1","title":"Finite volume schemes","text":""},{"location":"theory/finite_volume_schemes/#the-grid","title":"The grid","text":"<p>For simplicity, we use uniform discretization of \\([x_L, x_R]\\):</p> <ul> <li> <p>points:</p> \\[ \\begin{aligned}     x_j &amp;= x_L + \\qty(j+\\frac{1}{2})\\Delta x \\\\     \\Delta x &amp;= \\frac{x_R - x_L}{N+1} \\end{aligned} \\] <p>for \\(j=0,\\dots, N\\)</p> </li> <li> <p>midpoints:</p> \\[x_{j-\\frac{1}{2}} = x_j - \\frac{1}{2}\\Delta x = x_L + j\\Delta x\\] <p>for \\(j=0,\\dots, N+1\\)</p> </li> <li> <p>control volumes:</p> \\[\\Cell_j = [x_{j-1/2}, x_{j+1/2}]\\] <p>for \\(j=1,\\dots, N\\)</p> </li> <li> <p>uniform discretization of time:</p> \\[t^n = n\\Delta t\\] </li> </ul>"},{"location":"theory/finite_volume_schemes/#cell-averages","title":"Cell averages","text":"<p>The finite difference schemes approximates the point values, whereas the finite volume schemes aims to approximate the cell averages</p> \\[U_j^n \\approx \\frac{1}{\\Delta x}\\int_{\\Cell_j} U(x, t^n) \\dd x\\] <p>starting with</p> \\[U_j^0 = \\frac{1}{\\Delta x}\\int_{\\Cell_j} U_0(x) \\dd x\\]"},{"location":"theory/finite_volume_schemes/#integral-form","title":"Integral form","text":"<p>Assuming \\(U_j^n\\) is known for som time \\(t^n\\), we can integrate \\(\\eqref{eq:conservation_law}\\) over the swuare \\(\\Cell_j \\times [t^n, t^{n+1})\\) to get the next averages:</p> \\[\\int_{t^n}^{t^{n+1}} \\int_{\\Cell_j} U_t + f(U)_x \\dd x \\dd t = 0.\\] <p>Defining the flux \\(\\overline F_{j+1/2}^n\\) across the boundary \\(x_{j+1/2}\\) over the time interval \\([t^n, t^{n+1})\\):</p> \\[ \\begin{equation}         \\overline F_{j+1/2}^n = \\frac{1}{\\Delta t}\\int_{t^n}^{t^{n+1}} f(U(x_{j+1/2}, t)) \\dd t     \\label{eq:flux} \\end{equation} \\] <p>we can rewrite the above equation as</p> \\[ \\begin{equation}     U_j^{n+1} = U_j^n - \\frac{\\Delta t}{\\Delta x}\\qty(\\overline F_{j+1/2}^n - \\overline F_{j-1/2}^n).     \\label{eq:cell_average_update} \\end{equation} \\] <p>In other words, the change in cell averages is given by difference in fluxes across the cell boundaries. It now remains to approximate the fluxes.</p>"},{"location":"theory/finite_volume_schemes/#godunov-method","title":"Godunov method","text":"<p>Godunov noticed that the cell averages are constant in each cell \\(\\Cell_j\\) at each time. We thus get a Riemann problem at each cell interface \\(x_{j+1/2}\\):</p> \\[ \\begin{equation}     \\left\\{\\begin{aligned}         U_t + f(U)_x &amp; = 0 \\\\         U(x, t^n) &amp; = \\begin{cases}             U_j^n, &amp; x &lt; x_{j+1/2} \\\\             U_{j+1}^n, &amp; x &gt; x_{j+1/2}         \\end{cases}     \\end{aligned}\\right. \\label{eq:riemann_problem} \\tag{RP} \\end{equation} \\] <p>So at each time, we get a superposition of Riemann problems of the form \\(\\eqref{eq:riemann_problem}\\), at each interface. We have seen that the entropy solution is a combination of shocks, rarefactions and compound waves.</p> <p>As previously discussed, the solution \\(\\overline U_j(x,t)\\) of each Riemann problem \\(\\eqref{eq:riemann_problem}\\) is self-similar:</p> \\[ \\begin{equation}     \\overline U_j(x,t) = \\overline U_j\\qty(\\frac{x-x_{j+1/2}}{t-t^n}) = \\overline U_j(\\xi). \\label{eq:self_similar} \\end{equation}     \\] <p>However, the waves intersect after some time. The maximal speed of the waves is given by \\(\\displaystyle\\max_j \\abs{f'(U_j^n)}\\). Thus, to ensure that two neighboring waves do not intersect, they cannot travel in total more that \\(\\Delta x\\) in time \\(\\Delta t\\). This yields the CFL-condition</p> \\[ \\begin{equation}     \\max_j \\abs{f'(U_j^n)} \\frac{\\Delta t}{\\Delta x} \\leq \\frac{1}{2} \\label{eq:CFL_condition} \\tag{CFL} \\end{equation} \\] <p>Assume that this condition is satisfied, and consider the curve given by \\(\\xi = 0\\), i.e. the cell interface \\(x_{j+1/2}\\).</p> Claim: \\(f(\\overline U_j(0))\\) is well defined <p>By \\(\\eqref{eq:self_similar}\\), we have that \\(\\overline U_j\\) is constant whenever \\(\\xi\\) is, and particularly at \\(\\xi = 0\\):</p> \\[f(U(x_{j+1/2}, t)) = f(\\overline U_j(0))\\] <p>Along this curve, \\(\\overline U_j\\) is either continuous or not.</p> ContinuousDiscontinuous <p>In this case, we obviously have that</p> \\[f(\\overline U_j(0^-)) = f(\\overline U_j(0^+)),\\] <p>For \\(\\overline U_j\\) to be an entropy solution, the shock must satisfy the Rankine-Hugoniot condition</p> \\[ \\begin{equation}     \\jump{f(U)} = s\\jump{U}. \\label{eq:rankine_hugoniot} \\tag{RH} \\end{equation} \\] <p>with \\(s=0\\). We immidiately get that</p> \\[f(\\overline U_j(0^-)) = f(\\overline U_j(0^+))\\] <p>so \\(f(\\overline U_j(0)) = f(\\overline U_j(0^-)) = f(\\overline U_j(0^+))\\) is well defined.</p> <p>Now, we can define the (Riemann) edge-centered fluxes</p> <p>$$ \\begin{equation}     F_{j+1/2}^n := f(\\overline U_j(0)).     \\label{eq:edge_centered_flux} \\end{equation}</p> <p>Since this is constant in time, we can insert into \\(\\eqref{eq:flux}\\) and explicitly calculate</p> \\[\\overline F_{j+1/2}^n = F_{j+1/2}^n.\\] <p>Then, substituting into \\(\\eqref{eq:cell_average_update}\\), we get</p> \\[ \\begin{equation}     U_j^{n+1} = U_j^n - \\frac{\\Delta t}{\\Delta x}\\qty(F_{j+1/2}^n - F_{j-1/2}^n).     \\label{eq:godunov} \\end{equation} \\]"},{"location":"theory/finite_volume_schemes/#godunov-flux","title":"Godunov flux","text":"<p>It can be shown that the Riemann fluxes at the interfaces \\(x_{j+1/2}\\) is</p> \\[ \\begin{equation}     F_{j+1/2}^n = F(U_j^n, U_{j+1}^n)     = \\begin{cases}         \\displaystyle         \\min_{U_j^n \\leq \\theta \\leq U_{j+1}^n} f(\\theta), &amp; U_j^n \\leq U_{j+1}^n \\\\         \\displaystyle         \\max_{U_{j+1}^n \\leq \\theta \\leq U_j^n} f(\\theta), &amp; U_j^n &gt; U_{j+1}^n.     \\end{cases}     \\label{eq:godunov_flux} \\end{equation} \\] <p>This also holds for non-convex flux functions. Further, for flux functions \\(f\\) with a unique minimizer \\(\\omega\\), we can simplify further to</p> \\[ \\begin{equation}     F_{j+1/2}^n = F(U_j^n, U_{j+1}^n) = \\max\\qty{f\\qty(\\max\\{U_j^n, \\omega\\}), f\\qty(\\min\\{U_{j+1}^n, \\omega\\})}.     \\label{eq:godunov_flux_simplified} \\end{equation} \\]"},{"location":"theory/finite_volume_schemes/#numerical-example","title":"Numerical example","text":"<p>Now, using \\(\\eqref{eq:godunov_flux_simplified}\\), one can easily implement the Godunov method. Testing against Burgers' equation with initial conditions</p> \\[ \\begin{equation}     U_0(x) = \\begin{cases}         1, &amp; x &lt; 0 \\\\         0, &amp; x \\geq 0     \\end{cases} \\label{eq:initial_condition_shock} \\end{equation} \\] <p>we know the solution is a shock wave at \\(x = 1/2t\\).</p> <pre><code>x_L, x_R = -1, 1\nN = 50\nx = cell_centers(N, x_L, x_R)\nu0(x) = x &lt; 0 ? 1. : 0.\n\ngrid = UniformGrid1D(N, NeumannBC(), u0.(x), (x_L, x_R))\nsystem = ConservedSystem(BurgersEQ(), NoReconstruction(grid), GodunovFlux(0.), ForwardEuler(grid))\nsimulator = Simulator(system, grid, 0.)\n\ndt = 0.1 # max time step\nT = 1\nU, t = simulate_and_aggregate!(simulator, T, dt)\n\nanimate_solution(U', (x, t) -&gt; u0(x - 0.5t),\n                 x, t)\n</code></pre> <p></p> <p>The numerical solution approxumates this well, having a sharp shock at \\(x = 1/2t\\). Further, it seems stable without any oscillations. Next, for the initial condition</p> \\[ \\begin{equation}     U_0(x) = \\begin{cases}         -1, &amp; x &lt; 0 \\\\         1, &amp; x \\geq 0     \\end{cases} \\label{eq:initial_condition_rarefaction} \\end{equation} \\] <p>we expect a rarefaction wave between the curves \\(x = -t\\) and \\(x = t\\):</p> <pre><code>u0(x) = (x &gt; 0) * 2 - 1.\ngrid = UniformGrid1D(N, NeumannBC(), u0.(x), (x_L, x_R))\nsimulator = Simulator(system, grid, 0.)\nU, t = simulate_and_aggregate!(simulator, T, dt)\n\nanimate_solution(U',\n                 \"Approximate solution\",\n                 x, t)\n</code></pre> <p></p> <p>For a more complicated example, \\(U_0 = \\sin(4\\pi x)\\), we expect a compound wave:</p> <pre><code>u0(x) = sin(4\u03c0*x)\ngrid = UniformGrid1D(N, PeriodicBC(), u0.(x), (x_L, x_R))\nsimulator = Simulator(system, grid, 0.)\nU, t = simulate_and_aggregate!(simulator, T, dt)\n# U, t = godunov_scheme(f, df, \u03c9, U0, BC, dx, dt, T)\n\nanimate_solution(U',\n                 \"Approximate solution\",\n                 x, t)\n</code></pre> <p></p>"},{"location":"theory/finite_volume_schemes/#limitations","title":"Limitations","text":"<p>Despite having many disirable properties, the Godunov method has some limitations:</p> <ul> <li>It requires having an explicit formula for the solutions of the Riemann problems \\(\\eqref{eq:riemann_problem}\\). This is not always the case for systems of conservation laws.</li> <li>In the numerical flux \\(\\eqref{eq:edge_centered_flux}\\), the only required information is the flux at the interface. It may thus be unnecessary to solve an entire Riemann problem for this.</li> <li>For more complicated flux functions with multiple extremas, one cannot use \\(\\eqref{eq:godunov_flux_simplified}\\). Instead, one must solve the optimization problem \\(\\eqref{eq:godunov_flux}\\), which may be computationally expensive.</li> </ul>"},{"location":"theory/finite_volume_schemes/#approximate-riemann-solvers","title":"Approximate Riemann solvers","text":"<p>Instead of solving \\(\\eqref{eq:riemann_problem}\\) exactly, one can approximate them. These solutions can be used to define the numerical flux \\(F\\). Such schems are called approximate Riemann solvers.</p>"},{"location":"theory/finite_volume_schemes/#linearized-roe-solvers","title":"Linearized (Roe) solvers","text":"<p>One simple method is to linearize the conservation law \\(\\eqref{eq:conservation_law}\\):</p> \\[f(U)_x = f'(U)U_x \\approx \\hat A_{j+1/2} U_x.\\] <p>For example, one may use the Roe average</p> \\[\\hat A_{j+1/2} = \\begin{cases}     \\frac{f(U_{j+1}^n) - f(U_j^n)}{U_{j+1}^n - U_j^n}, &amp; U_{j+1}^n \\neq U_j^n \\\\     f'(U_j^n), &amp; U_{j+1}^n = U_j^n. \\end{cases}\\] <p>Now, we can obtain the numerical flux \\(F\\) by replacing \\(\\eqref{eq:riemann_problem}\\) with the linearized problem</p> \\[ \\begin{equation}     \\left\\{\\begin{aligned}         U_t + \\hat A_{j+1/2} U_x &amp; = 0 \\\\         U(x, t^n) &amp; = \\begin{cases}             U_j^n, &amp; x &lt; x_{j+1/2} \\\\             U_{j+1}^n, &amp; x &gt; x_{j+1/2}         \\end{cases}     \\end{aligned}\\right. \\label{eq:linearized_riemann_problem} \\tag{LRP} \\end{equation} \\] <p>Notice that this is just the linear transport equation with the explicit solution</p> \\[ \\begin{equation}     F_{j+1/2}^n = F^\\text{Roe}(U_j^n, U_{j+1}^n) = \\begin{cases}         f(U_j^n), &amp; \\hat A_{j+1/2} \\ge 0 \\\\         f(U_{j+1}^n), &amp; \\hat A_{j+1/2} &lt; 0.     \\end{cases}     \\label{eq:roe_flux} \\end{equation} \\] <p>The numerical scheme \\(\\eqref{eq:cell_average_update}\\) with this flux is called the Roe or Murman-Roe scheme. This preserves shocks well, but fails at rarefaction waves, for example our usual test case with initial data \\(\\eqref{eq:initial_condition_rarefaction}\\).</p>"},{"location":"theory/finite_volume_schemes/#central-schemes","title":"Central schemes","text":"<p>Due to the linearization, we only get a single wave travelling in a single direction depending on the sign of the Roe average \\(\\hat A\\). This is also the case for shocks for the exact solution, but not for rarefaction waves. Therefore, the Roe scheme fails for rarefaction waves. Hence, instead of linearizing the conservation law, one can approximate the solution of the Riemann problem with two waves travelling in opposite directions from the interface with speeds \\(s_{j+1/2}^l\\) and \\(s_{j+1/2}^r\\). Different such speeds yields different schemes. The approximate solution is then</p> \\[ U(x, t) = \\begin{cases}     U_j^n, &amp; x &lt; s_{j+1/2}^l t \\\\     U_{j+1}^*n, &amp; s_{j+1/2}^l t &lt; x &lt; s_{j+1/2}^r t \\\\     U_{j+1}^n, &amp; x &gt; s_{j+1/2}^r t. \\end{cases} \\] <p>The middle state \\(U_{j+1/2}^*\\) can be determined by using the Rankine Hugoniot condition:</p> \\[ \\begin{aligned}     f(U_{j+1}^n) - f_{j+1/2}^* &amp;= s_{j+1/2}^r(U_{j+1}^n - U_{j+1/2}^*) \\\\     f_{j+1/2}^* - f(U_j^n) &amp;= s_{j+1/2}^l(U_{j+1/2}^* - U_j^n), \\end{aligned} \\] <p>where \\(f_{j+1/2}^*\\) is the middle flux. Now, solving for \\(f_{j+1/2}^*\\), we get</p> \\[f_{j+1/2}^* = \\frac{s_{j+1/2}^r f(U_j^n) - s_{j+1/2}^l f(U_{j+1}^n) + s_{j+1/2}^r s_{j+1/2}^l(U_{j+1}^n - U_j^n)}{s_{j+1/2}^r - s_{j+1/2}^l}.\\] <p>This yields the numerical flux</p> \\[F_{j+1/2}^n = F(U_j^n, U_{j+1}^n) = f_{j+1/2}^*.\\]"},{"location":"theory/finite_volume_schemes/#lax-friedrichs-scheme","title":"Lax-Friedrichs scheme","text":"<p>By using the maximum speed the waves can travel without intersecting at the interface,</p> \\[s_{j+1/2}^l = -\\frac{\\Delta x}{\\Delta t}, \\quad s_{j+1/2}^r = \\frac{\\Delta x}{\\Delta t},\\] <p>we get the Lax-Friedrichs flux</p> \\[F_{j+1/2}^n = F^\\text{LxF}(U_j^n, U_{j+1}^n) = \\frac{f(U_j^n) + f(U_{j+1}^n)}{2} - \\frac{\\Delta x}{2\\Delta t}(U_{j+1}^n - U_j^n).\\] <p>The solutions are stable and non-oscillatory. Unlike the Roe scheme, it also approximates the entropy solution. However, shocks are not well preserved. See for example the usual Burgers' test case with initial data \\(\\eqref{eq:initial_condition_shock}\\):</p> <p></p>"},{"location":"theory/finite_volume_schemes/#rusanov-scheme","title":"Rusanov scheme","text":"<p>If we instead of using the maximum speeds use the speeds of propagation, we get the Rusanov scheme:</p> \\[s_{j+1/2}^l = -s_{j+1/2}, \\quad s_{j+1/2}^r = s_{j+1/2}\\] <p>with</p> \\[s_{j+1/2} = \\max\\qty{\\abs{f'(U_j^n)}, \\abs{f'(U_{j+1}^n)}}.\\] <p>Then, we get the Rusanov (or Local Lax-Friedrichs) flux</p> \\[ \\begin{aligned}     F_{j+1/2}^n     &amp;= F^\\text{Rus}(U_j^n, U_{j+1}^n) \\\\     &amp;= \\frac{f(U_j^n) + f(U_{j+1}^n)}{2}     - \\frac{\\max\\qty{\\abs{f'(U_j^n)}, \\abs{f'(U_{j+1}^n)}}}{2}(U_{j+1}^n - U_j^n). \\end{aligned} \\] <p>For the same problem as above with get</p> <p></p> <p>and with the initial data \\(\\eqref{eq:initial_condition_rarefaction}\\), we get</p> <p></p> <p></p> <p></p>"},{"location":"theory/finite_volume_schemes/#comparison","title":"Comparison","text":""},{"location":"theory/finite_volume_schemes/#consistent-conservative-and-monotone-schemes","title":"Consistent, conservative and monotone schemes","text":""},{"location":"theory/finite_volume_schemes/#conservative-schemes","title":"Conservative schemes","text":"<p>A numerical scheme approximating \\(\\eqref{eq:conservation_law}\\) can be formulated as</p> \\[ \\begin{equation}     U_j^{n+1} = H(U_{j-p}^n, \\dots, U_{j+p}^n) \\label{eq:general_scheme} \\end{equation} \\] <p>for some update function \\(H\\) depending on the \\(2p+1\\) points stencil \\(\\{U_{j-p}^n, \\dots, U_{j+p}^n\\}\\) for the scheme. Until now, we have worked with \\(3\\)-stencil schemes, i.e. \\(p=1\\). </p> <p>Definition (Conservative shceme)</p> <p>The generic scheme \\(\\eqref{eq:general_scheme}\\) approximating \\(\\eqref{eq:conservation_law}\\) is called conservative if</p> \\[\\sum_j U_j^{n+1} = \\sum_j U_j^n,\\] <p>ignoring the boundary conditions.</p> <p>Theorem</p> <p>Assume \\(H(0, \\dots, 0) = 0\\). </p> \\[ \\begin{gather*}     \\eqref{eq:general_scheme} \\text{ is conservative } \\\\     \\Updownarrow \\\\     \\text{There is a function } F_{j+1/2}^n = F(U_{j-p}^n, \\dots, U_{j+p}^n) \\text{ such that \\eqref{eq:general_scheme} can be written as } \\eqref{eq:cell_average_update}. \\end{gather*} \\] Proof \\(\\implies\\)\\(\\impliedby\\) <p>Define</p> \\[G(U_{-p}, \\dots, U_p) := \\frac{\\Dx}{\\Dt}(U_0 - H(U_{-p}, \\dots, U_p)).\\] <p>By conservation, we have that</p> \\[\\sum_j G(U_{j-p}^n, \\dots, U_{j+p}^n) = \\frac{\\Dx}{\\Dt}\\sum_j (U_j^n - H(U_{j-p}^n, \\dots, U_{j+p}^n)) = 0\\] <p>for any sequence \\(\\{U_j^n\\}_j\\).</p> \\(F_{i+1/2}\\)\\(F_{i-1/2}\\) <p>Now, define the sequence</p> \\[V_j^n :=  \\begin{cases}     0, &amp; j -i \\le -p \\lor j-i &lt; p \\\\     U_j^n, &amp; \\text{otherwise}. \\end{cases}\\] <p>Then, we have</p> \\[ \\begin{aligned}     0 &amp;= \\sum_j G(V_{j-p}^n, \\dots, V_{j+p}^n) \\\\     &amp;= \\underbrace{G(0, \\dots, 0, U_{1-p-i}^n) + \\dots + G(0, U_{1-p-i}^n, \\dots, U_{p-i}^n)}_{F_{i+1/2}} \\\\     &amp;\\quad + \\underbrace{G(U_{1-p-i}^n, \\dots, U_{p-i}^n, 0) + \\dots + G(U_{-p-i}^n, 0, \\dots, 0)}_B \\end{aligned} \\] <p>Now, define the sequence</p> \\[W_j^n :=  \\begin{cases}     0, &amp; j -i &lt; -p \\lor j-i &lt; p \\\\     U_j^n, &amp; \\text{otherwise}. \\end{cases}\\] <p>Then, we have</p> \\[ \\begin{aligned}     0 &amp;= \\sum_j G(W_{j-p}^n, \\dots, W_{j+p}^n) \\\\     &amp;= \\underbrace{G(0, \\dots, 0, U_{-p-i}^n) + \\dots + G(0, U_{-p-i}^n, \\dots, U_{p-i}^n)}_{F_{i-1/2}} \\\\     &amp;\\quad + G(U_{-p-i}^n, \\dots, U_{p-i}^n) \\\\     &amp;\\quad + \\underbrace{G(U_{1-p-i}^n, \\dots, U_{p-i}^n, 0) + \\dots + G(U_{-p-i}^n, 0, \\dots, 0)}_B \\end{aligned} \\] <p>This results in the form \\(\\eqref{eq:godunov}\\):</p> \\[ \\begin{aligned}     F_{i+1/2} + B &amp;= F_{i-1/2} + G(U_{-p-i}^n, \\dots, U_{p-i}^n) + B \\\\     F_{i+1/2} - F_{i-1/2} &amp;= \\frac{\\Dx}{\\Dt}(U_i^n - H(U_{i-p}^n, \\dots, U_{i+p}^n)) \\\\     U_i^{n+1} &amp;= U_i^n - \\frac{\\Dt}{\\Dx}(F_{i+1/2} - F_{i-1/2}). \\end{aligned} \\] <p>Then, we have</p> \\[U_j^{n+1} = H(U_{j-p}^n, \\dots, U_{j+p}^n) = U_j^n - \\frac{\\Delta t}{\\Delta x}\\qty(F_{j+1/2}^n - F_{j-1/2}^n).\\] <p>This yields a telescoping sum</p> \\[ \\begin{aligned}     \\sum_j U_j^{n+1} &amp;= \\sum_j \\qty[U_j^n - \\frac{\\Delta t}{\\Delta x}\\qty(F_{j+1/2}^n - F_{j-1/2}^n)] \\\\     &amp;= \\sum_j U_j^n \\end{aligned} \\]"},{"location":"theory/finite_volume_schemes/#consistent-schemes","title":"Consistent schemes","text":"<p>We now consider numerical fluxes \\(F_{j+1/2}^n\\) defined on \\(2p+1\\) stencils</p> \\[ \\begin{equation}     F_{j+1/2}^n = F(U_{j-p}^n, \\dots, U_{j+p}^n) \\label{eq:numerical_flux} \\end{equation} \\] <p>Definition (Consistency)</p> <p>The numerical flux \\(\\eqref{eq:numerical_flux}\\) is consistent if \\(F(U, \\dots, U) = f(U)\\) for all \\(U \\in \\R\\).</p> <p>Example</p> <p>All the numerical fluxes disussed above are consistent. Take for example Lax-Friedrichs:</p> \\[F^\\text{LxF}(U, U) = \\frac{f(U) + f(U)}{2} - \\frac{\\Delta x}{2\\Delta t}(U - U) = f(U).\\] <p>However, conservation and consistency does not imply stability or convergence. Take for example the Roe flux \\(\\eqref{eq:roe_flux}\\), which is trivially consistent but does not converge for certain problems.</p>"},{"location":"theory/finite_volume_schemes/#monotone-schemes","title":"Monotone schemes","text":"<p>Recall that entropy solutions to the conservation law \\(\\eqref{eq:conservation_law}\\) are monotinicity preserving. It would therefore be desirable to have numerical schemes that have a discrete version of this property.</p> <p>Definition (Monotone scheme)</p> <p>The numericals scheme \\(\\eqref{eq:general_scheme}\\) is monotone if it is non-decreasing in each argument, i.e. \\((\\nabla H)_i \\ge 0\\) for all \\(i\\).</p> <p>Lemma</p> <p>Let \\(F\\) be a locally Lipschitz continuous two-point numerical flux. Then we have</p> \\[\\eqref{eq:godunov} \\text{ is monotone} \\iff \\begin{aligned}     a &amp; \\mapsto F(a, b) \\text{ is non-decreasing for fixed } b \\\\     b &amp; \\mapsto F(a, b) \\text{ is non-increasing for fixed } a. \\end{aligned}\\] <p>and we get the following CFL type condition</p> \\[ \\begin{equation}     \\abs{\\pdv{F}{a}(v,w)} + \\abs{\\pdv{F}{b}(u,v)} \\le \\frac{\\Delta x}{\\Delta t} \\quad \\forall u, v, w. \\label{eq:monotone_CFL} \\end{equation} \\] <p>One cannowuse monotoicity to differentiate between robust and possibly non-robust schemes. For example, the Roe scheme is not monotone.</p>"},{"location":"theory/finite_volume_schemes/#stability-properties-of-monotone-schemes","title":"Stability properties of monotone schemes","text":"<p>Recall that the entropy solutions of \\(\\eqref{eq:conservation_law}\\) have</p> <ol> <li>\\(L^\\infty\\) bound</li> <li>\\(L^p\\) bounds</li> <li>\\(TV\\) bound</li> </ol> <p>and satisfy time constinuity. We will show that monotone schemes have these properties.</p>"},{"location":"theory/finite_volume_schemes/#l-bound","title":"L<sup>\u221e</sup> bound","text":"<p>Lemma</p> <p>Let \\(U_j^n\\) be the approximate solution using a consistent, monotone scheme of the form \\(\\eqref{eq:general_scheme}\\). Then we have</p> \\[\\min\\{U_{j-p}^n, \\dots, U_{j+p}^n\\} \\le U_j^{n+1} \\le \\max\\{U_{j-p}^n, \\dots, U_{j+p}^n\\},\\] <p>and in particular</p> \\[\\min_i U_j^0 \\le U_j^n \\le \\max_i U_j^0 \\quad \\forall n,j\\] Proof <p>Let \\(\\overline U_j^n = \\max\\{U_{j-p}^n, \\dots, U_{j+p}^n\\}\\) be the maximum of the stencil. Now, as \\(\\eqref{eq:general_scheme}\\) is monotone, we have</p> \\[ \\begin{aligned}     U_j^{n+1} &amp;= H(U_{j-p}^n, \\dots, U_{j+p}^n) \\\\     &amp;\\le H(\\overline U_{j-p}^n, U_{j-p+1}^n, \\dots, U_{j+p}^n) \\\\     &amp;\\vdots \\\\     &amp;\\le H(\\overline U_{j-p}^n, \\dots, \\overline U_{j+p}^n) \\\\     &amp;= \\overline U_j^n. \\end{aligned} \\] <p>Similarly, we get the minimum principle.</p> <p>Propagating this through time, we get the last claim too.</p>"},{"location":"theory/finite_volume_schemes/#entropy-inequalities-and-lp-bounds","title":"Entropy-inequalities and L\u1d56 bounds","text":"<p>In the continuous case, we used the entropy inequality to obtain \\(L^p\\) bounds. We will use discrete counterpart to the Kruzkov entropy inequality. The Crandall-Majda numerical entropy flux is given by</p> \\[Q_{j+1/2}^n = Q(U_j^n, U_{j+1}^n) = F(U_j^n \\lor k, U_{j+1}^n \\lor k) - F(U_j^n \\land k, U_{j+1}^n \\land k),\\] <p>where \\(a \\lor b = \\max\\{a, b\\}\\) and \\(a \\land b = \\min\\{a, b\\}\\). For consistent numerical fluxes, we see that this entropy flux is consistent with the Kruskov entropy flux:</p> \\[ \\begin{aligned}     Q(U, U) &amp;= f(U \\lor k) - f(U \\land k) \\\\     &amp;= \\sign(U - k)\\qty[f(U) - f(k)] \\\\     &amp;= q(U; k). \\end{aligned} \\] <p>Lemma (Crandall-Majda [CM80])</p> <p>Let \\(U_j^n\\) be the approximate solution using a consistent, conservative, monotone scheme of the form \\(\\eqref{eq:general_scheme}\\). Then we have the discrete entropy inequality</p> \\[ \\begin{equation}     \\abs{U_j^{n+1} - k}  - \\abs{U_j^n - k} + \\frac{\\Delta t}{\\Delta x}\\qty(Q_{j+1/2}^n - Q_{j-1/2}^n) \\le 0 \\quad \\forall n,j. \\label{eq:discrete_entropy_inequality} \\end{equation} \\] <p>Moreover, if \\(U_0 \\in L^1(\\R)\\), then</p> \\[\\sum_j \\abs{U_j^n} \\Delta x \\le \\norm{U_0}_{L^1(\\R)}.\\] Proof <p>The scheme is conservative, so we have</p> \\[ \\begin{aligned}     H(U_{j-p}^n \\lor k, &amp;\\dots, U_{j+p}^n \\lor k) \\\\     &amp; = U_j^n + \\frac{\\Delta t}{\\Delta x}\\qty(F(U_{j-p}^n \\lor k, \\dots, U_{j+p}^n \\lor k) - F(U_{j-p}^n \\land k, \\dots, U_{j+p}^n \\land k)). \\\\ \\end{aligned} \\] <p>and similarly for the minimum. Taking their difference, we get</p> \\[ \\begin{aligned}     H(U_{j-p}^n \\lor k, &amp;\\dots, U_{j+p}^n \\lor k)     - H(U_{j-p}^n \\land k, \\dots, U_{j+p}^n \\land k) \\\\     &amp; = U_j^n \\lor k - U_j^n \\land k     - \\frac{\\Delta t}{\\Delta x}\\qty(Q_{j+1/2}^n - Q_{j-1/2}^n) \\\\     &amp;= \\abs{U_j^{n+1} - k}  - \\frac{\\Delta t}{\\Delta x}\\qty(Q_{j+1/2}^n - Q_{j-1/2}^n) \\end{aligned} \\] <p>Further, by monotonicity, we have</p> \\[H(U_{j-p}^n \\lor k, \\dots, U_{j+p}^n \\lor k) \\ge \\begin{matrix}     U_j^{n+1} \\\\ k \\end{matrix} \\ge H(U_{j-p}^n \\land k, \\dots, U_{j+p}^n \\land k),\\] <p>so inserting into the above equation, we get the first claim.</p> <p>Now, let \\(k=0\\) and sum over \\(j\\) to get the second claim.</p>"},{"location":"theory/finite_volume_schemes/#tv-bound","title":"TV bound","text":"<p>If we interpret the cell averages as step functions, then the total variation reduces to the sum of the jumps:</p> \\[\\norm{U^n}_{TV(\\R)} = \\sum_j \\abs{U_j^n - U_{j-1}^n}.\\] <p>We can rewrite the finite volume scheme \\(\\eqref{eq:godunov}\\) in the incremental form</p> \\[ \\begin{equation}     U_j^{n+1} = U_j^n + C_{j+1/2} \\qty(U_{j+1}^n - U_j^n) - D_{j-1/2} \\qty(U_j^n - U_{j-1}^n)     \\label{eq:incremental_form} \\end{equation} \\] <p>where</p> \\[C_{j+1/2}^n = \\frac{\\Delta t}{\\Delta x} \\frac{f(U_j^n) - F_{j+1/2}^n}{U_{j+1}^n - U_j^n}, \\quad D_{j+1/2}^n = \\frac{\\Delta t}{\\Delta x} \\frac{f(U_{j+1}^n) - F_{j+1/2}}{U_{j+1}^n - U_j^n}.\\] <p>Then, wecanuse the following result:</p> <p>Hartem's Lemma [Har83]</p> <p>Let \\(U_j^n\\) be computed with \\(\\eqref{eq:incremental_form}\\).</p> <ol> <li> <p>If \\(C_{j+1/2}^n, D_{j+1/2}^n \\ge 0\\) and \\(C_{j+1/2}^n + D_{j+1/2}^n \\le 1\\) for all \\(n, j\\), then</p> \\[\\norm{U^{n+1}}_{TV(\\R)} \\le \\norm{U^n}_{TV(\\R)}.\\] </li> <li> <p>If \\(C_{j+1/2}^n, D_{j-1/2}^n \\ge 0\\) and \\(C_{j+1/2}^n + D_{j-1/2}^n \\le 1\\) for all \\(n, j\\), then</p> \\[\\norm{U^{n+1}}_{L^\\infty} \\le \\norm{U^n}_{L^\\infty}.\\] </li> </ol> Proof 1.2. <p>Using \\(\\eqref{eq:incremental_form}\\), we get the difference</p> \\[ \\begin{aligned}     U_{j+1}^{n+1} - U_j^{n+1}     \\le&amp; \\qty(1-C_{j+1/2}^n - D_{j+1/2}^n)\\qty(U_{j+1}^n - U_j^n) \\\\     &amp;+ C_{j+3/2}^n \\qty(U_{j+2}^n - U_{j+1}^n) \\\\     &amp;+ D_{j-1/2}^n \\qty(U_j^n - U_{j-1}^n). \\end{aligned} \\] <p>Taking the absolute value, we get the inequality</p> \\[ \\begin{aligned}     \\abs{U_{j+1}^{n+1} - U_j^{n+1}}     &amp;\\le \\qty(1-C_{j+1/2}^n - D_{j+1/2}^n)\\abs{U_{j+1}^n - U_j^n} \\\\     &amp;\\quad + C_{j+3/2}^n \\abs{U_{j+2}^n - U_{j+1}^n} \\\\     &amp;\\quad + D_{j-1/2}^n \\abs{U_j^n - U_{j-1}^n}. \\end{aligned} \\] <p>Summing over \\(j\\), we get a telescoping sum, resulting in</p> \\[\\sum_j \\abs{U_{j+1}^{n+1} - U_j^{n+1}} \\le \\sum_j \\abs{U_{j+1}^n - U_j^n}.\\] <p>Rewriting \\(\\eqref{eq:incremental_form}\\) as</p> \\[U_j^{n+1} = C_{j+1/2}^n U_{j+1}^n + \\qty(1 - C_{j+1/2}^n - D_{j-1/2}^n) U_j^n + D_{j-1/2}^n U_{j-1}^n,\\] <p>we see that \\(U_j^{n+1}\\) is a convex combination of \\(U_{j-1}^n, U_j^n, U_{j+1}^n\\). Thus, \\(U_j^{n+1}\\) is bounded by the maximum and minimum of these values, so we get the claim.</p> <p>It turns out that consistent, conservative, monotone schemes satisfies these criteria, so we can use this lemma to show that the schemes are TVD.</p> <p>Lemma</p> <p>Monotone, consistent, conservative 3-point schemes are TVD under the CFL condition \\(\\eqref{eq:monotone_CFL}\\).</p> Proof <p>The coefficients are positive:</p> \\[ \\begin{align*}     C_{j+1/2}^n &amp;= \\frac{\\Delta t}{\\Delta x} \\frac{f(U_j^n) - F_{j+1/2}^n}{U_{j+1}^n - U_j^n} \\\\     &amp;= \\frac{\\Delta t}{\\Delta x} \\frac{F(U_j^n, U_j^n) - F_{j+1/2}^n}{U_{j+1}^n - U_j^n}     \\tag*{(Consistency)} \\\\     &amp;\\ge 0     \\tag*{(Monotonicity)} \\end{align*} \\] <p>Similarly for \\(D_{j-1/2}^n\\). Further, we have</p> \\[ \\begin{align*}     C_{j+1/2}^n &amp;= \\frac{\\Delta t}{\\Delta x} \\frac{F(U_j^n, U_j^n) - F_{j+1/2}^n}{U_{j+1}^n - U_j^n} \\\\     &amp; \\le \\frac{\\Delta t}{\\Delta x} \\norm{\\pdv{F}{a}}_{L^\\infty}     \\tag*{(Lipschitz flux)} \\end{align*} \\] <p>and similarly for \\(D_{j-1/2}^n\\). Then, under the CFL condition \\(\\eqref{eq:monotone_CFL}\\), we get </p> \\[1 - C_{j+1/2}^n - D_{j-1/2}^n \\ge 1 - \\frac{\\Delta x}{\\Delta t} \\qty(\\abs{\\pdv{F}{a}} + \\abs{\\pdv{F}{b}}) \\ge 0.\\]"},{"location":"theory/finite_volume_schemes/#time-continuity","title":"Time continuity","text":"<p>In the continuous case, we have the time continuity property</p> \\[\\norm{U(\\cdot, t) - U(\\cdot, s)}_{L^1(\\R)} \\le |t-s| \\norm{f}_{\\text{Lip}} \\norm{U_0}_{TV(\\R)}.\\] <p>We can show that the discrete solution has a similar property.</p> <p>Lemma</p> <p>Let \\(U_j^n\\) computed using  consistent, conservative and monotone scheme with Lipschitz continuous numerical fluxe \\(F=F(a,b)\\) whose Lipschitz constant is \\(C_F\\). Then we get</p> \\[\\Delta x \\sum_j \\abs{U_j^n - U_j^m} \\le 2C_F \\abs{t^n - t^m} \\norm{U_0}_{TV(\\R)}.\\] Proof <p>Taking the absolute value of \\(\\eqref{eq:godunov}\\) and summing over \\(j\\), we get</p> \\[ \\begin{aligned}     \\Delta x \\sum_j \\abs{U_j^{n+1} - U_j^n}     &amp;= \\Delta t \\sum_j \\abs{F_{j+1/2}^n - F_{j-1/2}^n} \\\\     &amp;\\le \\Delta t \\sum_j \\abs{F(U_j^n, U_{j+1}^n) - F(U_j^n, U_j^n)} \\\\     &amp; \\quad + \\Delta t \\sum_j \\abs{F(U_j^n, U_j^n) - F(U_{j-1}^n, U_j^n)} \\\\     &amp; \\le \\Delta t \\sum_j C_F \\abs{U_{j+1}^n - U_j^n} + \\Delta t \\sum_j C_F \\abs{U_j^n - U_{j-1}^n} \\\\     &amp;= 2C_F \\Delta t \\sum_j \\abs{U_{j+1}^n - U_j^n}. \\end{aligned} \\] <p>Now, taking the difference from \\(k=n\\) to \\(k=m\\) and using the TVD property, we get</p> \\[ \\begin{aligned}     \\Delta x \\sum_j \\abs{U_j^n - U_j^m}     &amp; \\le \\Delta x \\sum_{k=n}^{m-1} \\qty(\\sum_j \\abs{U_j^{k+1} - U_j^k}) \\\\     &amp; \\le 2C_F \\Delta t \\sum_{k=n}^{m-1} \\norm{U^k}_{TV(\\R)} \\\\     &amp; \\le 2C_F \\abs{t^n - t^m} \\norm{U_0}_{TV(\\R)}. \\end{aligned} \\]"},{"location":"theory/finite_volume_schemes/#convergence-of-monotone-schemes","title":"Convergence of monotone schemes","text":"<p>We have now shown that conserative, consistent and monotone schemes are stable in \\(L^\\infty\\) and \\(TV\\), are TVD and satisfy the discrete entropy inequality. We will use this to prove convergence. Further, Lax-Wendroff theorem shows that the limit is the entropy solution. To simplify notation, we will set</p> \\[ \\newcommand{\\UDx}{U^{\\Delta x}} \\newcommand{\\pDx}{\\phi^{\\Delta x}} \\UDx(x, t) = U_j^n \\quad \\text{for } (x, t) \\in \\Cell_j \\times [t^n, t^{n+1}). \\] <p>Lax-Wendroff theorem</p> <p>Let \\(U_j^n\\) an approxiamate solution of \\(\\eqref{eq:conservation_law}\\) using a consistent and conservative finite volume scheme. Assume that the numerical flux is differentiable and that \\(U_j^0\\) are the cell averages of the initial data.</p> <p>Assume further that</p> <ul> <li>\\(U_0 \\in L^\\infty(\\R)\\),</li> <li>\\(\\UDx\\) is uniformly bounded in \\(\\Delta x\\),</li> <li>there exists a function \\(U \\in L_{\\text{loc}}^1(\\R \\times R_+)\\) such that \\(\\UDx \\to U\\) in this space as \\(\\Delta x, \\Delta t \\to 0\\).</li> </ul> <p>Then, \\(U\\) is a weak solution of \\(\\eqref{eq:conservation_law}\\) with initial data \\(U_0\\).</p> Proof <p>Let \\(\\phi \\in C_c^\\infty(\\R \\times \\R_+)\\), be a test function. Next, sum \\(\\eqref{eq:godunov}\\) over \\(j, n\\):</p> \\[ \\begin{aligned}     0 &amp;= \\Dx \\Dt \\sum_j \\sum_{n=0}^\\infty     \\qty(\\frac{U_j^{n+1} - U_j^n}{\\Dt} + \\frac{F_{j+1/2}^n - F_{j-1/2}^n}{\\Dx}) \\phi_j^n \\\\     &amp;= - \\Dx \\sum_j U_j^0 \\phi_j^0 - \\Dx \\sum_j \\sum_{n=0}^\\infty     \\qty(U_j^{n+1} \\frac{\\phi_j^{n+1} - \\phi_j^n}{\\Dt} + F_{j+1/2}^n \\frac{\\phi_{j+1}^n - \\phi_j^n}{\\Dx}) \\end{aligned} \\] <p>As \\(\\phi\\) has compact support, the above sum is finite. Define \\(\\phi_j^n = \\phi(x_j, t^n)\\) and denote \\(\\pDx(x, t)\\) similarly to \\(\\UDx\\). Then, we can express the above sums as integrals:</p> \\[ \\begin{aligned}     0 &amp;= \\underbrace{\\int_\\R \\UDx(x, 0) \\pDx(x, 0) \\dd x     + \\int_\\R \\int_0^\\infty \\UDx(x, t + \\Dt) \\frac{\\pDx(x, t + \\Dt) - \\pDx(x, t)}{\\Dt} \\dd t \\dd x}_{I_1^{\\Delta x}} \\\\     &amp;\\quad + \\underbrace{\\int_\\R \\int_0^\\infty F\\qty(\\UDx(x, t), \\UDx(x + \\Dx, t)) \\frac{\\pDx(x + \\Dx, t) - \\pDx(x, t)}{\\Dx} \\dd t \\dd x}_{I_2^{\\Delta x}}. \\end{aligned} \\] <p>We have that \\(\\abs{\\UDx} \\le \\abs{U}\\) and \\(\\abs{\\pDx} \\le \\abs{\\phi}\\), so we can use the dominated convergence theorem for the first two integrals \\(I_1^{\\Delta x}\\) yielding</p> \\[I_1^{\\Delta x} \\xrightarrow{\\Delta x, \\Delta t \\to 0} \\int_\\R U_0(x) \\phi(x, 0) \\dd x + \\int_\\R \\int_0^\\infty U \\phi_t \\dd t \\dd x.\\] <p>Next, rewrite \\(I_2^{\\Delta x}\\) as</p> \\[ \\begin{aligned}     I_2^{\\Delta x} &amp;= \\underbrace{\\int_\\R \\int_0^\\infty f(\\UDx(x, t)) \\frac{\\pDx(x + \\Dx, t) - \\pDx(x, t)}{\\Dx} \\dd t \\dd x}_{I_{2,1}^{\\Delta x}} \\\\     &amp; \\quad\\quad + \\underbrace{\\int_\\R \\int_0^\\infty \\qty[F\\qty(\\UDx(x, t), \\UDx(x + \\Dx, t)) - f(\\UDx(x, t))]     \\frac{\\pDx(x + \\Dx, t) - \\pDx(x, t)}{\\Dx} \\dd t \\dd x}_{I_{2,2}^{\\Delta x}}. \\end{aligned} \\] Claim: \\(I_{2,2}^{\\Delta x} \\xrightarrow{\\Delta x, \\Delta t \\to 0} 0\\) <p>Recall that \\(F\\) is differentiable and \\(U \\in L^\\infty(\\R \\times \\R_+)\\), so we have</p> \\[ \\begin{aligned}     &amp; \\abs{F\\qty(\\UDx(x, t), \\UDx(x + \\Dx, t)) - f(\\UDx(x, t))} \\\\     &amp; \\quad\\quad = \\abs{F(\\UDx(x, t), \\UDx(x + \\Dx, t)) - F(\\UDx(x, t), \\UDx(x, t))} \\\\     &amp; \\quad\\quad \\le \\tilde C \\abs{\\UDx(x + \\Dx, t) - \\UDx(x, t)}. \\end{aligned} \\] <p>we can use the above inequality for \\(I_{2,2}^{\\Delta x}\\) to get</p> \\[\\abs{I_{2,2}^{\\Delta x}} \\le \\tilde C \\norm{\\phi_x}_{L^\\infty} \\iint_{\\supp \\phi_x} \\abs{\\UDx(x + \\Dx, t) - \\UDx(x, t)} \\dd x \\dd t\\] <p>Using approximation by \\(C^\\infty\\) functions, we get thedesired result.</p> <p>Let \\(\\psi_l \\in C^\\infty(\\R)\\) be a sequence of functions converging to \\(U\\) in \\(L_{\\text{loc}}^1(\\R\\times \\R_+)\\). The integrand can be bounded by</p> \\[ \\begin{aligned}     &amp; {\\abs{\\UDx(x + \\Dx, t) - \\psi_l(x,t)}}     + \\abs{\\UDx(x, t) - \\psi_l(x,t)} \\\\     &amp; \\quad \\quad \\le \\underbrace{\\abs{\\UDx(x + \\Dx, t) - U(x+\\Dx, t)}}_{J_1}     + \\underbrace{\\abs{U(x+\\Dx, t) - \\psi_l(x,t)}}_{J_2} \\\\     &amp; \\quad \\quad \\quad + \\underbrace{\\abs{\\UDx(x, t) - U(x, t)}}_{J_3}     + \\underbrace{\\abs{U(x, t) - \\psi_l(x,t)}}_{J_4}. \\end{aligned} \\] <p>By dominated convergence, \\(\\iint_{\\supp \\phi_x} J_i \\dd x \\dd t \\to 0\\) as \\(\\Delta x, \\Delta t \\to 0\\) for \\(i=1,3\\). By definition of \\(\\psi_l\\), the same holds for \\(i=4\\). Convince yourself that it stays true for \\(i=2\\).</p> <p>Again, by diminated convergence, we get that</p> \\[I_{2,1}^{\\Delta x} \\xrightarrow{\\Delta x, \\Delta t \\to 0} \\int_\\R \\int_0^\\infty f(U(x, t)) \\phi_t \\dd t \\dd x.\\] <p>Combining the results, we get</p> \\[0 = \\int_\\R U_0(x) \\phi(x, 0) \\dd x + \\int_\\R \\int_0^\\infty U \\phi_t + f(U) \\phi_t \\dd t \\dd x.\\] <p>Lemma</p> <p>Assume the same conditions as in the Lax-Wendroff theorem, including that the discrete entropy inequality \\(\\eqref{eq:discrete_entropy_inequality}\\) holds. Then,</p> \\[U = \\lim_{\\Delta x, \\Delta t \\to 0} \\UDx\\] <p>is the entropy solution of \\(\\eqref{eq:conservation_law}\\).</p> Proof <p>The proof is almost identical to that of the Lax-Wendroff theorem. We start with the discrete entropy inequality \\(\\eqref{eq:discrete_entropy_inequality}\\) instead of \\(\\eqref{eq:godunov}\\) and use a non-negative test function \\(\\phi\\). Then, following the same steps as in the proof of the Lax-Wendroff theorem, we get</p> \\[0 \\ge I_1^{\\Delta x} + I_2^{\\Delta x}\\] <p>where</p> \\[ \\begin{aligned}     I_1^{\\Delta x} &amp;= \\int_\\R \\abs{\\UDx(x, 0) - k} \\pDx(x, 0) \\dd x \\\\     &amp; \\quad\\quad+ \\int_\\R \\int_0^\\infty \\abs{\\UDx(x, t + \\Dt) - k} \\frac{\\pDx(x, t + \\Dt) - \\pDx(x, t)}{\\Dt} \\dd t \\dd x, \\\\     I_2^{\\Delta x} &amp;= \\int_\\R \\int_0^\\infty Q\\qty(\\UDx(x, t), \\UDx(x + \\Dx, t)) \\frac{\\pDx(x + \\Dx, t) - \\pDx(x, t)}{\\Dx} \\dd t \\dd x. \\end{aligned} \\] <p>As with in the proof of the Lax-Wendroff theorem, we have that</p> \\[I_1^{\\Delta x} \\xrightarrow{\\Delta x, \\Delta t \\to 0} \\int_\\R \\abs{U_0(x)-k} \\phi(x, 0) \\dd x + \\int_\\R \\int_0^\\infty \\abs{U-k} \\phi_t \\dd t \\dd x.\\] <p>We also rewrite \\(I_2^{\\Delta x} = I_{2,1}^{\\Delta x} + I_{2,2}^{\\Delta x}\\) as in Lax-Wendroff. Again,</p> \\[I_{2,1}^{\\Delta x} \\xrightarrow{\\Delta x, \\Delta t \\to 0} \\int_\\R \\int_0^\\infty q(U(x, t); k) \\phi_t \\dd t \\dd x.\\] <p>Doing as in the proof of the Lax-Wendroff theorem, we see that \\(I_{2,2}^{\\Delta x}\\) vanishes. Combining the results, we get</p> \\[0 \\ge \\int_\\R \\abs{U_0(x)-k} \\phi(x, 0) \\dd x + \\int_\\R \\int_0^\\infty \\abs{U-k} \\phi_t + q(U; k) \\phi_t \\dd t \\dd x.\\] <p>Now, we can use monotinicity, conservation, consistency and the following two known results to show convergence.</p> Ascoli's Theorem <p>Let \\((x, d_X)\\) be a metric space and \\(K \\subset X\\) be relatively compact. Further, let</p> \\[\\qty{u_k : [0, T] \\to K}_k\\] <p>be a sequence of uniformly Lipschitz continuous functions, i.e.</p> \\[d_X(u_k(t), u_k(s)) \\le C \\abs{t-s} \\quad \\forall k\\in \\N, t, s \\in [0, T].\\] <p>Then, there exists a subsequence \\(u_{k_\\ell}\\) converging to a Lipschitz continuous function \\(u\\) uniformly on \\([0, T]\\).</p> Helly's Theorem [Giu84, T.1.19] <p>Let \\(a, b \\in \\R\\) and \\(K \\subset L^1([a, b])\\). If there exists a number \\(M&gt;0\\) such that</p> \\[\\sup_{U \\in K} \\|U\\|_{BV([a, b])} \\le M,\\] <p>then \\(K\\) is relatively compact in \\(L^1([a, b])\\).</p> <p>If additionally, \\(K \\subset L^1(\\R)\\) and</p> \\[\\lim_{R\\to\\infty} \\sup_{U\\in K} \\int_{\\R \\setminus [-R, R]} \\abs{U(x)} \\dd x = 0,\\] <p>then \\(K\\) is relatively compact in \\(L^1(\\R)\\).</p> <p>For the convergence, we define the piecewise affine (in time) function</p> \\[\\UDx(x, t) = \\frac{t^{n+1} - t}{\\Dt} U_j^n + \\frac{t - t^n}{\\Dt} U_j^{n+1}, \\quad x \\in \\Cell_j, t \\in [t^n, t^{n+1}).\\] <p>Theorem</p> <p>Consider the conservation law \\(\\eqref{eq:conservation_law}\\) with \\(f \\in C^1(\\R)\\) and \\(U_0 \\in BV(\\R)\\), and a conmsistent, conservative, monotone finite volumes scheme under the CFL condition \\(\\eqref{eq:monotone_CFL}\\). Assume further that there is some \\(c&gt;0\\) such that \\(\\frac{\\Dt}{\\Dx} \\ge c\\).</p> <p>Then, \\(\\UDx \\to U\\) in \\(L^1(\\R \\times [0,T])\\) and \\(U\\) is the entropy solution.</p> Proof <p>Let \\(K = \\qty{U = \\UDx(\\cdot, t) \\mid t \\in [0, T], \\Dx &gt; 0}\\) be functions \\(U : \\R \\to \\R\\) attained at some time \\(t\\) by the scheme.</p> Claim: The conditions of Helly's Theorem are satisfied <p>By Crandall-Majda, we have that \\(K\\) is bounded in \\(L^1(\\R)\\) by \\(\\norm{U_0}_{L^1(\\R)}\\). We have also shown that the scheme is TVD, so \\(K \\subset BV(\\R)\\).</p> <p>For the second part of the theorem, we have that \\(U_0 \\in L^1(\\R)\\), so</p> \\[\\forall \\eps &gt; 0 \\exists\\, r &gt; 0 : \\left\\{\\begin{aligned}     &amp; \\abs{U_0(x)} \\le \\eps \\quad \\forall \\abs{x} &gt; r, \\\\     &amp; \\int_{\\R \\setminus [-r, r]} \\abs{U_0(x)} \\dd x \\le \\eps. \\end{aligned}\\right.\\] <p>Additionally, by monotinicity, we have that</p> \\[\\min\\qty{U_{j-1}^n, U_j^n, U_{j+1}^n} \\le U_j^{n+1} \\le \\max\\qty{U_{j-1}^n, U_j^n, U_{j+1}^n}, \\quad \\forall n, j.\\] <p>So, propagating at the speed \\(1/c\\), we get that</p> \\[\\UDx(x, t) \\le \\eps \\quad \\forall \\abs{x} &gt; R, t\\in[0, T],\\] <p>where \\(R = r + T/c\\). Next, let \\(J \\in \\N\\) be such that \\(R \\in \\Cell_J\\). Then, we sum the discrete entropy inequality \\(\\eqref{eq:discrete_entropy_inequality}\\) over \\(\\abs{j} &gt; J\\) and over \\(n=0,\\dots,N\\) for \\(k=0\\):</p> \\[ \\begin{aligned}     \\sum_{\\abs{j} &gt; J} \\sum_{n=0}^N \\qty(\\abs{U_j^{n+1}} - \\abs{U_j^n})     + \\frac{\\Dt}{\\Dx} \\sum_{\\abs{j} &gt; J} \\sum_{n=0}^N \\qty(Q_{j+1/2}^n - Q_{j-1/2}^n)     &amp; \\le 0 \\\\     \\sum_{\\abs{j} &gt; J} \\qty(\\abs{U_j^{N+1}} - \\abs{U_j^0})     + \\frac{\\Dt}{\\Dx} \\sum_{n=0}^N \\qty(Q_{-J-1/2}^n - Q_{J+1/2}^n)     &amp;\\le 0 \\end{aligned} \\] <p>Now, \\(U_j^0\\) is the cell average of \\(U_0\\), so we further get the bound</p> \\[\\Dx\\sum_{\\abs{j} &gt; J} \\abs{U_j^{N+1}} \\le \\int_{\\R \\setminus [-R, R]} \\abs{U_0} \\dd x + \\Dt \\sum_{n=0}^N \\qty(\\abs{Q_{-J-1/2}^n} + \\abs{Q_{J+1/2}^n}).\\] <p>Finally, for \\(t \\in [t^m, t^{m+1})\\), we have</p> \\[ \\begin{aligned}     \\int_{\\R \\setminus [-R, R]} \\abs{\\UDx} \\dd x     &amp;\\le \\Dx \\sum_{\\abs{j} &gt; J} \\qty(\\abs{U_j^m} + \\abs{U_j^{m+1}}) \\\\     &amp;\\le 2\\int_{\\R \\setminus [-R, R]} \\abs{U_0} \\dd x     + 2\\Dt \\sum_{n=0}^m \\qty(\\abs{Q_{-J-1/2}^n} + \\abs{Q_{J+1/2}^n}) \\\\     &amp;\\le 2\\eps + 2\\Dt \\sum_{n=0}^N \\qty(\\abs{Q_{-J-1/2}^n} + \\abs{Q_{J+1/2}^n}). \\end{aligned} \\] Claim: \\(\\abs{Q_{\\pm J \\pm 1/2}^n} \\le 2C_F\\eps\\) <p>Recall that \\(F\\) is Lipschitz continuous, so</p> \\(\\sign{U_J^n} = \\sign{U_{J+1}^n}\\)\\(\\sign{U_J^n} \\neq \\sign{U_{J+1}^n}\\) \\[ \\begin{aligned}     \\abs{Q_{J+1/2}^n} &amp;= \\abs{F(U_J^n, U_{J+1}^n) - F(0, 0)} \\\\     &amp; \\le \\abs{F(U_J^n, U_{J+1}^n) - F(U_J^n, 0)} + \\abs{F(U_J^n, 0) - F(0, 0)} \\\\     &amp; \\le C_F \\qty(\\abs{U_{J+1}^n} + \\abs{U_J^n}) \\end{aligned} \\] \\[ \\begin{aligned}     \\abs{Q_{J+1/2}^n} &amp;= \\abs{F(U_J^n, 0) - F(0, U_{J+1}^n)} \\\\     &amp; \\le \\abs{F(U_J^n, 0) - F(0, 0)} + \\abs{F(0, 0) - F(0, U_{J+1}^n)} \\\\     &amp; \\le C_F \\qty(\\abs{U_J^n} + \\abs{U_{J+1}^n}). \\end{aligned} \\] <p>Similarly for \\(Q_{-J-1/2}^n\\). Recall further that \\(J\\) is chosen such that \\(U_J^n, U_{J+1}^n \\le \\eps\\) for all \\(n\\). Hence, we get the desired result.</p> <p>Then, we get the bound</p> \\[\\int_{\\R \\setminus [-R, R]} \\abs{\\UDx} \\dd x \\le 2\\eps \\qty(1 + 4C_F T)\\] <p>independent of \\(t\\) and \\(\\Dx\\). This proves the claim.</p> <p>So \\(K\\) is relatively compact in \\(L^1(\\R)\\). Then, by Ascoli's theorem, there exists a subsequence \\(\\Dx'\\) and \\(U \\in L^1(\\R \\times [0, T])\\) such that \\(\\UDx{}^{'} \\to U\\). By Lax-Wendroff, \\(U\\) is the entropy solution.</p>"},{"location":"theory/linear_transport_eqs/","title":"Linear transport equations","text":""},{"location":"theory/linear_transport_eqs/#linear-transport-equations","title":"Linear transport equations","text":"<p>The simplest case of the one-dimensional version of the transport equation,</p> \\[ \\begin{equation}     U_t + a(x, t) U_x = 0 \\quad \\text{ in } \\R \\times \\R_+, \\label{eq:transport} \\end{equation} \\] <p>is when the velocity field \\(a\\) is constant. The Cauchy problem is solved using the method of characteristics, where the solution is constant along the characteristic curves \\(x = x_0 + a t\\). The solution is then</p> \\[ \\begin{equation}     U(x, t) = U_0(x - a t) \\label{eq:transport_const} \\end{equation} \\] <p>for any \\((x,t) \\in \\R \\times \\R_+\\). We see that the initial data is transported with the velocity \\(a\\). For more general cases, the characteristics may not be possible to solve explicitly. However, we can obtain some information of the sulutions with the following a priori energy estimate:</p> <p>Lemma</p> <p>Assume \\(U\\) is a smooth solution of the transport equation decaying to zero at infinity for all \\(t \\in R_+\\) and \\(a \\in C^1(\\R, \\R_+)\\). Then, \\(U\\) satisfies the energy bound</p> \\[     \\int_{\\R} U^2(x, t) \\dd x \\leq e^{\\norm{a}_{C^1}t} \\int_\\R U_0^2(x) \\dd x. \\] Proof <p>Follows by multiplying the transport equation by \\(U\\) and integrating over space. Then, use that \\(U\\) decays to zero at infinity and apply Gr\u00f6nwall's inequality.</p> <p>The lemma shows that the energy is bounded. Using another functional, the assumptions on \\(U\\) can be relaxed:</p> <p>Lemma</p> <p>Assume \\(U\\) is a smooth bounded solution of the transport equation. Then, we have</p> \\[     \\sup_{x \\in \\R} \\abs{U(x, t)} \\leq \\norm{U_0}_{L^\\infty(\\R)} \\] <p>for any \\(t &gt; 0\\). </p> Proof <p>For any \\((x, t) \\in \\R \\times \\R_+\\), there exists \\(\\xi \\in \\R\\) such that \\(U(x, t) = U_0(\\xi)\\)</p> <p></p> <p></p>"},{"location":"theory/linear_transport_eqs/#finite-difference-schemes-for-the-transport-equation","title":"Finite difference schemes for the transport equation","text":"<p>For some velocity fields \\(a(x,t)\\), it may not be possible to derive an explicit formula for the characteristic equation. We thus use numerical methods to approximate the solutions of the transport equation.</p> <p></p> <p></p>"},{"location":"theory/linear_transport_eqs/#discretization","title":"Discretization","text":"<p>For simplicity, assume that the velocity field is positive. AS \\(\\R\\) is unbounded, we truncate the domain into \\(\\Omega = [x_L, X_R]\\). Thus, we must impose boundary conditions, which will be discussed below. For simplicity, we use a uniform mesh of mesh size \\(\\Delta x\\) with \\(N+1\\) points \\(x_j\\):</p> \\[     x_L = x_0 &lt; x_1 &lt; \\cdots &lt; x_N = x_R \\] <p>We further choose some terminal time \\(T\\) and divide into \\(M+1\\) points \\(t^n = n \\Delta t\\). We set the initial approximaition \\(U_j^0 := U_0(x_j)\\) and update the next approximation \\(U_j^{n+1}\\) using a finite difference scheme.</p> <p></p> <p></p>"},{"location":"theory/linear_transport_eqs/#centered-finite-difference-scheme","title":"Centered finite difference scheme","text":"<p>One such scheme is the forward difference in time and cetral difference in space approximating \\((\\ref{eq:transport_const})\\):</p> \\[     \\frac{U_j^{n+1} - U_j^n}{\\Delta t} + \\frac{a(U_{j+1}^n - U_{j-1}^n)}{2 \\Delta x} = 0,     \\quad 0 &lt; j &lt; N. \\] <p></p> <p></p>"},{"location":"theory/linear_transport_eqs/#example","title":"Example","text":"<p>We consider the domain \\([0, 1]\\) with initial data</p> \\[     U_0(x) = \\sin(2\\pi x) \\] <pre><code>u0(x) = sin(2*pi*x)\n</code></pre> <p>and \\(a = 1\\). Since the data is periodic, we impose periodic boundary conditions. Numerically, we implement this by setting</p> \\[     U_{0}^n = U_N^n, \\quad U_{N+1}^n = U_1^n \\] <p>Thus, on the boundary, \\(j = 0, N\\), we have</p> \\[ \\begin{align*}     \\frac{U_1^{n+1} - U_1^n}{\\Delta t} + \\frac{a(U_2^n - U_N^n)}{2 \\Delta x} = 0, \\\\     \\frac{U_N^{n+1} - U_N^n}{\\Delta t} + \\frac{a(U_1^n - U_{N-1}^n)}{2 \\Delta x} = 0. \\end{align*} \\] <p>For the first time step \\(n = 1\\), we have</p> \\[ \\begin{equation}     U_j^1 = U_0(x_j) - \\frac{\\Delta t}{2 \\Delta x} (U_0(x_{j+1}) - U_0(x_{j-1})) \\label{eq:transport_first} \\end{equation} \\] <p>Using a grid of \\(50\\) mesh points, simulating to time \\(T = 3\\), we get the following result:</p> <p></p> <p>After some time, the solution diverges. Intuitively, the information should propagate from left to right. However, the scheme uses information from both sides. This can be explained rigorously using the the discrete energy</p> \\[     E^n = \\frac{1}{2} \\Delta x \\sum_j (U_j^n)^2. \\] <p>We know that the exact solution have bounded energy. We say that a scheme is energy stable if \\(E^n \\leq E^0\\) for all \\(n\\).</p> <p>Lemma</p> <p>Let \\(U_j^n\\) be the solutions computed with the central difference scheme. Then, we have the  following dicsrete energy estimate:</p> \\[     E^{n+1} = E^n + \\frac{\\Delta x}{2} \\sum_j (U_j^{n+1} - U_j^n)^2 \\] <p>Thus, the energy grows at each time step for any choice of \\(\\Delta x\\) and \\(\\Delta t\\).</p> Proof <p>Similar to the proof of the continuous energy estimate and using the identity</p> \\[     d_2(d_1 - d_2) = \\frac{1}{2}\\qty(d_1^2 - d_2^2) \\] <p></p> <p></p>"},{"location":"theory/linear_transport_eqs/#upwind-scheme","title":"Upwind scheme","text":"<p>To respect the flow of information, we can use forward and backward differences in space depending on the direction of propagation of information, i.e.</p> \\[     \\frac{U_j^{n+1} - U_j^n}{\\Delta t}     + \\frac{a^+ (U_j^n - U_{j-1}^n)}{\\Delta x} + \\frac{a^- (U_{j+1}^n - U_j^n)}{\\Delta x} = 0. \\] <p>Information is \"carried by the wind\", hence the name upwind. The above equations can be written as</p> \\[     \\frac{U_j^{n+1} - U_j^n}{\\Delta t} + \\frac{a (U_{j+1}^n - U_{j-1}^n)}{2 \\Delta x}     = \\frac{\\abs{a}}{2\\Delta x} (U_{j+1}^n - 2 U_j^n + U_{j-1}^n). \\] <p>We see we have the central difference scheme with a diffusion term; the right hand side approximates \\(\\frac{\\Delta x \\abs{a}}{2} U_xx\\). Thus, it adds numerical viscosity to the unstable central difference scheme, which will play a crucial role later.</p> <p>Now, we do the same numerical experiment as previously with \\(a = 1\\):</p> <p> </p> <p>We see that stability depends on the relation \\(\\frac{\\Delta t}{\\Delta x}\\). </p> <p>Lemma</p> <p>If the mesh parameters satisfy the condition</p> \\[\\frac{\\abs{a} \\Delta t}{\\Delta x} \\leq 1,\\] <p>then the upwind solution satisfies the estimate</p> \\[E^{n+1} \\leq E^n\\] <p>so the scheme is conditionally stable.</p> Proof <p>Start similarly to the proof of the unconditional unstability of the central difference scheme and use the mentioned identity several times.</p> <p>The above condition is called A CFL condition. We also have \\(L^1\\) and \\(L^\\infty\\) stability:</p> <p>Lemma</p> <p>Assume the above CFL condition holds. Then, the solutions of the upwind scheme satisfy</p> \\[     \\norm{U^{n+1}}_{L^1} \\le \\norm{U^n}_{L^1}, \\quad     \\norm{U^{n+1}}_{L^\\infty} \\le \\norm{U^n}_{L^\\infty}. \\] Proof <p>The first inequality follows from \\(U_j^{n+1}\\)being a convex combination of \\(U_{j-1}^n\\), \\(U_j^n\\) and \\(U_{j+1}^n\\).</p> <p></p> <p></p>"},{"location":"theory/linear_transport_eqs/#discontinuous-initial-data","title":"Discontinuous initial data","text":"<p>We now consider the transport equation with \\(a = 1\\) in the domain \\([0, 1]\\) with initial data</p> \\[     U_0(x) = \\begin{cases}         2, &amp; x &lt; 0.5, \\\\         1, &amp; x \\geq 0.5.     \\end{cases} \\] <p>This yields the discontinuous solution \\(U(x, t) = U_0(x - t)\\). We use the upwind scheme with \\(N = 50\\) and \\(N = 200\\) mesh points.</p> <p> </p>"},{"location":"theory/nonlinear_hyperbolic_systems/","title":"Nonlinear hyperbolic systems in one dimension","text":"<p>Most equations of the form</p> \\[ \\newcommand{\\U}{\\mathbf{U}} \\newcommand{\\f}{\\mathbf{f}} \\newcommand{\\r}{\\mathbf{r}} \\begin{equation}     \\begin{aligned}         \\partial_t \\U + \\partial_x \\f(\\U) &amp;= 0 \\\\         \\U(x, 0) &amp;= \\U_0(x)     \\end{aligned} \\label{eq:nonlinear_hyperbolic_system} \\end{equation} \\] <p>from physics are nonlinear hyperbolic systems. We will now look at </p> <ul> <li>structural properties and</li> <li>well-posedness,</li> </ul> <p>in particular, for the Riemann problem</p> \\[ \\begin{equation}     \\begin{aligned}         \\partial_t \\U + \\partial_x \\f(\\U) &amp;= 0 \\\\         \\U(x, 0) &amp;= \\begin{cases}             \\U_L, &amp; x &lt; 0 \\\\             \\U_R, &amp; x &gt; 0,         \\end{cases}     \\end{aligned} \\label{eq:riemann_problem} \\tag{RP} \\end{equation} \\] <p>an determine the general form of the entropy solution. We will assume \\(\\U \\in L_\\text{loc}^1(\\R \\times \\R_+, \\mathcal U)\\) for some \\(\\mathcal U \\subset \\R^m\\), for which \\(\\eqref{eq:nonlinear_hyperbolic_system}\\) makes sense.</p> <p>As with the scalar case, \\(\\U\\) can develop discontinuities in finite time, so we need to interprate \\(\\eqref{eq:nonlinear_hyperbolic_system}\\) in the weak sense:</p> \\[ \\begin{equation}     \\int_{\\R_+} \\int_\\R \\U \\partial_t \\phi + \\f(\\U) \\partial_x \\phi \\, \\dd x \\, \\dd t     + \\int_\\R \\U_0(x) \\phi(x, 0) \\, \\dd x = 0     \\label{eq:weak_nonlinear_hyperbolic_system} \\end{equation} \\] <p>for all test functions \\(\\phi \\in C_c^\\infty(\\R \\times \\R_+)\\). Similarly, one can derive the rankine-hugoniot condition: If \\(\\U\\) is piecewise \\(C^1\\) with only jump discontinuities, then \\(\\U\\) is a weak solution of \\(\\eqref{eq:nonlinear_hyperbolic_system}\\) if and only if it is a classical solution wherever it is \\(C^1\\) and satisfies</p> \\[ \\begin{equation}     s = \\frac{[\\![\\f(\\U)]\\!]}{[\\![\\U]\\!]}     \\label{eq:rankine_hugoniot}     \\tag{RH} \\end{equation} \\] <p>where \\(s = \\gamma'(t)\\) is the speed of the discontinuity. We now have \\(2m + 1\\) unknowns, \\(\\U_L\\), \\(\\U_R\\), and \\(s\\), but only \\(m\\) equations. The entropy condition will deal with the last \\(m+1\\) unknowns.</p>"},{"location":"theory/nonlinear_hyperbolic_systems/#structural-properties","title":"Structural properties","text":"<p>To develop existence and uniqueness results, we will need to impose some assumptions on \\(\\f\\). </p> <p>Definition (Hyperbolic system)</p> <p>The system of equations \\(\\eqref{eq:nonlinear_hyperbolic_system}\\) is called hyperbolic if the Jacobian matrix \\(\\f'(\\U)\\) is real diagonizable for all \\(\\U \\in \\mathcal U\\):</p> \\[\\f'(\\U) = R(\\U) \\Lambda(\\U) R(\\U)^{-1}\\] <p>It is called strictly hyperbolic if</p> \\[\\lambda_1(\\U) &lt; \\lambda_2(\\U) &lt; \\ldots &lt; \\lambda_m(\\U).\\] <p>Definition</p> <p>The \\(j\\)-th wave-family is genuinely nonlinear if for all \\(\\U \\in \\mathcal U\\),</p> \\[\\nabla \\lambda_j(\\U) \\cdot \\r_j(\\U) \\neq 0.\\] <p>It is called linearly degenerate if for all \\(\\U \\in \\mathcal U\\),</p> \\[\\nabla \\lambda_j(\\U) \\cdot \\r_j(\\U) = 0.\\] Example (Scalar conservation law) <p>For \\(m=1\\), the system reduces to a scalar conservation law. Then, we only have a single eigenvalue \\(\\lambda(U) = f'(U) \\in \\R\\) and can choose \\(r(U) = 1\\). Thus, \\(\\eqref{eq:nonlinear_hyperbolic_system}\\) is always hyperbolic.</p> <p>Additionally,</p> \\[\\nabla \\lambda(U) \\cdot r(U) = f''(U).\\] <p>We therefore have that it is</p> <ul> <li>genuinely nonlinear if \\(f\\) is strictly convex or concave,</li> <li>linearly degenerate if \\(f\\) is affine.</li> </ul> Example (Shallow water equations) <p>A model for water waves in a shallow body of water is given by</p> \\[\\begin{aligned}     \\partial_t h + \\partial_x (hv) &amp;= 0, \\\\     \\partial_t (hv) + \\partial_x \\qty(\\frac{1}{2} g h^2 + hv^2) &amp;= 0 \\end{aligned}\\] <p>where the height \\(h\\) and the momentum \\(m:=hv\\) are the conserved quantities. We can write this as \\(\\eqref{eq:nonlinear_hyperbolic_system}\\) with</p> \\[\\U = \\begin{pmatrix} h \\\\ m \\end{pmatrix}, \\quad \\f(\\U) = \\begin{pmatrix} m \\\\ \\frac{1}{2} g h^2 + \\frac{m^2}{h} \\end{pmatrix}.\\] <p>This gives the Jacobian</p> \\[\\f'(\\U) = \\begin{pmatrix} 0 &amp; 1 \\\\ gh - \\frac{m^2}{h^2} &amp; \\frac{2m}{h} \\end{pmatrix},\\] <p>and the eigenvalues and eiegenvectors</p> \\[\\lambda_\\pm = v \\pm c,\\quad \\r_\\pm = \\begin{pmatrix} 1 \\\\ v \\pm c \\end{pmatrix}.\\] <p>The values if \\(\\U\\) for which the equation makes sense are</p> \\[\\mathcal U = \\qty{ (h, m) \\in \\R^2 \\mid h &gt; 0 }.\\] <p>The families of waves are genuinely nonlinear, as</p> \\[\\nabla \\lambda_\\pm \\cdot \\r_\\pm = \\mp \\frac{3}{2} \\sqrt{\\frac{g}{h}} \\neq 0.\\]"},{"location":"theory/nonlinear_hyperbolic_systems/#simple-solutions","title":"Simple solutions","text":"<p>From now on, we will assume that all the families of waves are either genuinely nonlinear or linearly degenerate. Additionally, if the \\(j\\)-th family is genuinely nonlinear, we will normalize \\(\\r_j\\) such that</p> \\[\\nabla \\lambda_j(\\U) \\cdot \\r_j(\\U) = 1 \\quad \\forall \\U \\in \\mathcal U\\] <p>We will now fix \\(\\U_L \\in \\mathcal U\\) and find all \\(U_R\\) such that we get a rarefaction wave or a shock wave in the Riemann problem \\(\\eqref{eq:riemann_problem}\\).</p>"},{"location":"theory/nonlinear_hyperbolic_systems/#rarefaction-waves","title":"Rarefaction waves","text":"<p>A rarefaction wave is a smooth solution of \\(\\eqref{eq:nonlinear_hyperbolic_system}\\) connecting \\(\\U_L\\) and \\(\\U_R\\). Recall that the solution is invariant under the transformation \\((x, t) \\mapsto (\\alpha x, \\alpha t)\\) so it takes the form \\(\\newcommand{\\u}{\\mathbf{u}}\\U(x, t) = \\u(x/t)\\), where \\(\\u \\in C^1(\\R, \\R^m)\\). Inserting into \\(\\eqref{eq:nonlinear_hyperbolic_system}\\) gives</p> \\[\\u'(\\xi) f'(u(\\xi)) = \\xi \\u'(\\xi).\\] <p>Then, we either have \\(\\u'(\\xi) = 0\\) or \\(\\xi\\) is an eigenvalue of the Jacobian \\(f'(\\u(\\xi))\\). In the latter case, we have that</p> \\[\\u'(\\xi) = \\r_j(\\u(\\xi)), \\quad \\xi = \\lambda_j(\\u(\\xi))\\] <p>for some \\(j\\). Now, if there are some \\(\\xi_L, \\xi_R \\in \\R\\) such that \\(\\u(\\xi_L) = \\U_L\\) and \\(\\u(\\xi_R) = \\U_R\\), they must be \\(\\xi_L = \\lambda_j(\\U_L)\\) and \\(\\xi_R = \\lambda_j(\\U_R)\\). The rarefaction solution of \\(\\eqref{eq:riemann_problem}\\) is then given by</p> \\[\\U(x, t) = \\left\\{\\begin{aligned}     \\U_L, &amp;&amp;&amp; \\frac{x}{t} &lt; \\lambda_j(\\U_L) \\\\     \\u\\qty(\\frac{x}{t}), &amp;&amp; \\lambda_j(\\U_L) &lt;  &amp;\\frac{x}{t} &lt; \\lambda_j(\\U_R) \\\\     \\U_R, &amp;&amp;  \\lambda_j(\\U_R) &lt; &amp; \\frac{x}{t} \\end{aligned}\\right.\\]"},{"location":"theory/scalar_cons_laws/","title":"Scalar conservation laws","text":"<p>In the previous chapter, we considered the scalar conservation law</p> \\[ U_t + a(x,t) U_x = 0 \\] <p>This was linear, as \\(a\\) was a given function. However, the velocity field can depend on the solution, and the equation becomes nonlinear. For example, we can have</p> \\[ a(x, t) = U(x, t) \\] <p>and we get the inviscid Burgers' equation, which can be written on the conservative form</p> \\[ \\begin{equation}     U_t + \\qty(\\frac{1}{2} U^2)_x = 0 \\label{eq:burgers} \\end{equation} \\] <p>whenever \\(U\\) is smooth. More generally, we may have</p> \\[ \\begin{equation}     U_t + f(U)_x = 0 \\label{eq:scalar_cons_law} \\end{equation} \\] <p>where \\(f\\) is a given flux function. This is a nonlinear scalar conservation law.</p>"},{"location":"theory/scalar_cons_laws/#charachteristics-for-burgers-equation","title":"Charachteristics for Burgers' equation","text":"<p>The characteristics for the Burgers' equation are given by</p> \\[ \\begin{aligned}     x'(t) &amp;= U(x(t), t) \\\\     x(0) &amp;= x_0 \\end{aligned} \\] <p>We consider first the initial data</p> \\[ U_0(x) = \\begin{cases}     U_L, &amp; x &lt; 0 \\\\     U_R, &amp; x &gt; 0 \\end{cases} \\] <p>The soluiton is constant along the charachteristics, so</p> \\[ x(t) = U_0(x_0) t + x_0. \\] <p>Consider \\(U_L = 1\\) and \\(U_R = 0\\). Then, we clearly see that the characteristics will intersect. Thus, we get a discontinuity in the solution. This can also happen for smooth initial data.</p>"},{"location":"theory/scalar_cons_laws/#weak-solutions","title":"Weak solutions","text":"<p>We therefore need to use the weak formulation</p> \\[ \\begin{equation}     \\int_{\\R_+} \\int_\\R U \\phi_t + f(U) \\phi_x \\dd x \\dd t + \\int_\\R U_0(x) \\phi(x, 0) \\dd x = 0 \\label{eq:weak_scalar_cons_law} \\end{equation} \\] <p>for any test function \\(\\phi \\in C_c^1(\\R \\times \\R_+)\\).</p>"},{"location":"theory/scalar_cons_laws/#the-rankine-hugoniot-condition","title":"The Rankine-Hugoniot condition","text":"<p>In nature, the discontinuities appear as shock waves. These must saisfy some conditions. Assume that we have a weak solution \\(U\\) that is smooth on two regions \\(\\Omega^-, \\Omega^+\\) separated by a shock wave. Let the shock wave be defined by the curve \\(x = \\gamma(t)\\). Lastly, assume that \\(U \\in C^1(\\Omega^-) \\cap C^1(\\Omega^+)\\). Then, we have</p> \\[ \\begin{aligned}     \\int_\\Omega U \\phi_t + f(U) \\phi_x \\dd \\Omega     =&amp; -\\int_{\\Omega^+} (U_t + f(U)_x) \\phi \\dd \\Omega     + \\int_{\\partial \\Omega^+} \\bm F(U^+) \\cdot \\bm \\nu \\phi \\dd \\Omega \\\\     &amp;- \\int_{\\Omega^-} (U_t + f(U)_x) \\phi \\dd \\Omega     + \\int_{\\partial \\Omega^-} \\bm F(U^-) \\cdot \\bm \\nu \\phi \\dd \\Omega \\\\     =&amp; 0 \\end{aligned} \\] <p>where \\(\\bm F(U) = (U, f(U))\\). Up to normalizaton, we have that \\(\\bm \\nu = (1, -s(t))\\). Where \\(s(t) = \\gamma'(t)\\) is the speed of the shock curve. Then we have</p> \\[ \\int_{\\Omega^+\\cup\\Omega^-} \\underbrace{\\qty(U_t + f(U)_x)}_0 \\phi \\dd \\Omega + \\int_{\\gamma} \\qty(s(t)\\qty(U^+ - U^-) - \\qty(f(U^+) - f(U^-))) \\phi \\dd \\Omega = 0 \\] <p>This needs to hold for all test functions and \\(U^+, U^-\\) are smooth on \\(\\gamma\\), so we get the Rankine-Hugoniot condition</p> \\[ \\begin{equation}     s(t) \\qty(U^+ - U^-) = f(U^+) - f(U^-) \\label{eq:rankine_hugoniot} \\tag{RH} \\end{equation} \\] <p>where \\(U^\\pm\\) are evaluated on \\((\\gamma(t),t)\\).</p> <p>Theorem</p> <p>Let \\(\\gamma \\in C^1(\\R_+)\\) and \\(U \\in L^\\infty(\\R \\times \\R_+)\\) be of the form</p> \\[ U(x, t) = \\begin{cases}     U^+(x,t), &amp; x &lt; \\gamma(t) \\\\     U^-(x,t), &amp; x &gt; \\gamma(t) \\end{cases} \\] <p>where \\(U^\\pm \\in C^1(\\R \\times \\R_+)\\). Then, \\(U\\) solves \\(\\eqref{eq:scalar_cons_law}\\) weakly if and only if</p> <ul> <li>\\(U^\\pm\\) solves it in the classical sense, and</li> <li>the shock speed \\(s(t)\\) satisfies the Rankine-Hugoniot condition \\(\\eqref{eq:rankine_hugoniot}\\) at \\(x = \\gamma(t)\\).</li> </ul>"},{"location":"theory/scalar_cons_laws/#lax-entropy-condition","title":"Lax entropy condition","text":"<p>We consider again the Burgers' equation \\(\\eqref{eq:burgers}\\) on the Riemann problem with \\(U_L = 1\\) and \\(U_R = 0\\). The yields the shock speed</p> \\[     s(t) = \\frac{\\frac{U_R^2}{2} - \\frac{U_L^2}{2}}{U_R - U_L} \\equiv \\frac{1}{2} \\] <p>The shock starts at \\(x = 0\\), so we get the weak solution</p> \\[ \\begin{equation}     U(x, t) = \\begin{cases}         1, &amp; x &lt; \\frac{1}{2} t \\\\         0, &amp; x &gt; \\frac{1}{2} t.     \\end{cases} \\label{eq:riemann_solution_1} \\end{equation} \\] <p>This satisfies \\(\\eqref{eq:weak_scalar_cons_law}\\) and we see that the characteristsics flow into the shock. </p> <p>Next, consider the Riemann problem with \\(U_L = 0\\) and \\(U_R = 1\\). Then, the characteristics do not fill the plane. However, we see that </p> \\[ \\begin{equation}     U(x, t) = \\begin{cases}         0, &amp; x &lt; \\frac{1}{2} t \\\\         1, &amp; x &gt; \\frac{1}{2} t     \\end{cases} \\label{eq:riemann_solution_2} \\end{equation} \\] <p>is a solution of the weak formulation \\(\\eqref{eq:weak_scalar_cons_law}\\). However, one can easily construct another solution</p> \\[ \\begin{equation}     U(x, t) = \\begin{cases}         0, &amp; x &lt; \\frac{1}{3} t \\\\         \\frac{2}{3}, &amp; \\frac{1}{3} t &lt; x &lt; \\frac{5}{6} t \\\\         0, &amp; x &gt; \\frac{5}{6} t.     \\end{cases} \\label{eq:riemann_solution_3} \\end{equation} \\] <p>This nonuniqueness is implicit in the weak formulation, so we need to impose extra conditions. Observe that the charachteristics of \\(\\eqref{eq:riemann_solution_1}\\) flow into the shock, while the characteristics of \\(\\eqref{eq:riemann_solution_2}\\) and \\(\\eqref{eq:riemann_solution_3}\\) flow out from the shock. Intuitively, information should always flow from the initial data. This is the case for \\(\\eqref{eq:riemann_solution_1}\\), but not for the other two. For the Burgers' equation, this requirement can be expressed as</p> \\[ U^- &gt; s &gt; U^+. \\] <p>For convex \\(f\\), this can be generalized to the Lax entropy condition</p> \\[ \\begin{equation}     f'(U^-) \\leq s \\leq f'(U^+). \\end{equation} \\] <p>Exercise</p> <p>We know that</p> \\[ U(x, t) = \\begin{cases}     U_L, &amp; x &lt; s t \\\\     U_R, &amp; x &gt; s t \\end{cases} \\] <p>is a weak solution of the Riemann problem.</p> <p>Assume that \\(f\\) is strictly convex and that \\(U_L &gt; U_R\\). Show that \\(U\\) satisfies the Lax entropy condition.</p> <p>Similarly, show that if \\(U_L &lt; U_R\\), then \\(U\\) does not satisfy the Lax entropy condition.</p> <p>It turns out that in the last case, a continuous solution exists.</p>"},{"location":"theory/scalar_cons_laws/#rarefaction-waves","title":"Rarefaction waves","text":"<p>We will assume that \\(f\\) is strictly convex. Note that scaling \\((x, t) \\mapsto (\\lambda x, \\lambda t)\\) does not change the solution and that the initial data is invariant under this scaling. Thus, it is natural to assume that the solution only depends on the ratio \\(\\xi:=\\frac{x}{t}\\):</p> \\[ U(x, t) = V\\qty(\\frac{x}{t}). \\] <p>Substituting this into the conservation law \\(\\eqref{eq:scalar_cons_law}\\), we get</p> \\[ (f'(V(\\xi)) - \\xi) V'(\\xi) = 0. \\] <p>As \\(f'\\) is strictly increasing, the inverse function \\(f'^{-1}\\) exists. Thus, we get the rarefaction wave</p> \\[ V'(x/t) = \\qty(f')^{-1}(x/t). \\] <p>Then we can construct a weak solution satisfying the Lax entropy condition by</p> \\[ \\begin{equation}     U(x, t) = \\begin{cases}         U_L, &amp; x \\le f'(U_L) t \\\\         (f')^{-1}(x/t), &amp; f'(U_L) t &lt; x \\le f'(U_R) t \\\\         U_R, &amp; x &gt; f'(U_R) t.     \\end{cases} \\label{eq:rarefaction_solution} \\end{equation} \\]"},{"location":"theory/scalar_cons_laws/#entropy-solutions","title":"Entropy solutions","text":"<p>The entropy condition is a local condition at shocks, so it may be difficoult to apply it in proofs of global stability estimates. We will here derive an equivalent global condition.</p>"},{"location":"theory/scalar_cons_laws/#the-entropy-condition","title":"The entropy condition","text":"<p>We add a viscous term to the conservation law:</p> \\[ \\begin{equation}     U_t^\\eps + f(U^\\eps)_x = \\eps U_{xx}^\\eps \\label{eq:convection-diffusion} \\end{equation} \\] <p>and later let \\(\\eps \\to 0\\). We now have a parabolic convection-diffusion equation. These equations have \\(C^\\infty\\) solutions. Now, let \\(\\eta : \\R \\to \\R\\) be a strictly convex function and define</p> \\[ q(U) = \\int_0^U f'(v)\u00a0\\nu'(v) \\dd v. \\] <p>We call \\((\\eta, q)\\) an entropy pair and respectively the entropy function and the entropy flux. Note that \\(q' = f' \\nu'\\). Then, multiplying \\(\\eqref{eq:convection-diffusion}\\) with \\(\\eta'(U^\\eps)\\), we get</p> \\[ \\eta(U^\\eps)_t + q(U^\\eps)_x = \\eps \\eta(U^\\eps)_{xx} - \\eps \\eta''(U^\\eps) (U^\\eps_x)^2. \\] <p>By the conevxity of \\(\\eta\\), the last term is nonnegative, so we have</p> \\[ \\eta(U^\\eps)_t + q(U^\\eps)_x \\leq \\eps \\eta(U^\\eps)_{xx}. \\] <p>Then, for the vanishing viscosity solution \\(\\displaystyle U = \\lim_{\\eps \\to 0} U^\\eps\\), we get the entropy condition</p> \\[ \\begin{equation}     \\eta(U)_t + q(U)_x \\leq 0. \\label{eq:entropy_condition} \\tag{EI} \\end{equation} \\] <p>Again, this must be interpreted in the sense of distributions:</p> \\[ \\int_{\\R_+} \\int_\\R \\eta(U) \\phi_t + q(U) \\phi_x \\dd x \\dd t + \\int_\\R \\eta(U_0(x)) \\phi(x, 0) \\dd x \\leq 0 \\] <p>Definition (Entropy solution)</p> <p>A function \\(U \\in L^\\infty(\\R \\times \\R_+)\\) is an entropy solution of \\(\\eqref{eq:scalar_cons_law}\\) if both</p> <ul> <li>\\(U\\) is a weak solution of \\(\\eqref{eq:scalar_cons_law}\\), and</li> <li>\\(U\\) satisfies the entropy condition \\(\\eqref{eq:entropy_condition}\\) for all entropy pairs \\((\\eta, q)\\).</li> </ul>"},{"location":"theory/scalar_cons_laws/#kruzkov-entropy-condition","title":"Kruzkov Entropy Condition","text":"<p>Of special importance is the family of entropy pairs</p> \\[ \\begin{aligned}     \\eta(U; c) &amp;= \\abs{U - c} \\\\     q(U; c) &amp;= \\sign(U - c) [f(U) - f(c)]. \\end{aligned} \\] <p>for \\(c \\in \\R\\). \\(U\\)satisfies the Kruzkov entropy condition if</p> \\[ \\begin{equation}     \\abs{U - c}_t + \\sign(U - c) [f(U) - f(c)]_x \\leq 0 \\label{eq:kruzkov_entropy_condition} \\tag{KEC} \\end{equation} \\] <p>in the weak sence for all \\(c \\in \\R\\). This is important because of the following lemma:</p> <p>Lemma</p> <p>Let \\(U \\in L^\\infty(\\R \\times \\R_+)\\).</p> \\[ U \\text{ is an entropy solution of } \\eqref{eq:scalar_cons_law} \\iff U \\text{ satisfies } \\eqref{eq:kruzkov_entropy_condition} \\] Proof \\(\\implies\\)\\(\\impliedby\\) <p>Follows from the definition of entropy solutions.</p> Weak solutionEntropy condition <p>Let \\(a, b \\in \\R\\). such that \\(a \\le U \\le b\\) a.e. in \\(\\R \\times \\R_+\\). Then, selecting \\(c=a\\), we get by \\(\\eqref{eq:kruzkov_entropy_condition}\\)</p> \\[ U_t + f(U)_x \\leq 0 \\quad \\text{a.e. in } \\R \\times \\R_+. \\] <p>Similarly, selecting \\(c=b\\), we get</p> \\[ U_t + f(U)_x \\geq 0 \\quad \\text{a.e. in } \\R \\times \\R_+. \\] <p>This yields</p> \\[ U_t + f(U)_x = 0 \\quad \\text{a.e. in } \\R \\times \\R_+. \\] <p>so \\(U\\) is a weak solution. </p> <p>Any convex combination can be approximated by linear combinations of \\(\\eta(U; a)\\). Thus, the entropy condition holds for all entropy pairs.</p> <p>Theorem</p> <p>Let \\(\\gamma \\in C^1(\\R_+)\\) be a curve and \\(s = \\gamma'\\) be its speed. Assume \\(U \\in L^\\infty(\\R \\times \\R_+)\\) is a weak solution of \\(\\eqref{eq:scalar_cons_law}\\) of the form</p> \\[ U(x, t) = \\begin{cases}     U^-(x, t), &amp; x &lt; \\gamma(t) \\\\     U^+(x, t), &amp; x &gt; \\gamma(t) \\end{cases} \\] <p>where \\(U^\\pm \\in C^1\\). Then, the following are equivalent:</p> <ol> <li>\\(U\\) is an entropy solution.</li> <li> <p>At \\(x = \\gamma(t)\\), \\(U\\) satisfies</p> \\[\\jump{q(U)} - s\\jump{U} \\le 0\\] <p>for all entropy pairs \\((\\eta, q)\\).</p> </li> <li> <p>For all \\(v \\in (U^-, U^+)\\), we have</p> \\[ \\begin{equation}     \\frac{f(v) - f(U^-)}{v - U^-} \\ge s \\ge \\frac{f(v) - f(U^+)}{v - U^+} \\label{eq:oleinik-E} \\tag{OCD} \\end{equation} \\] <p>along \\(x = \\gamma(t)\\). Also called the Oleinik codition \\(E\\).</p> </li> <li> <p>If \\(f\\) is convex/concave, then</p> \\[f'(U^-) \\ge s \\ge f'(U^+)\\] <p>along \\(x = \\gamma(t)\\).</p> </li> </ol> Proof <p>The other direction is left as an exercise for the reader.</p> 1. \\(\\implies\\) 2.2. \\(\\implies\\) 3.3. \\(\\implies\\) 4. <p>\\(U\\) is an entropy solution, so we have that</p> \\[\\abs{U - c}_t + \\sign(U - c) [f(U) - f(c)]_x \\le 0 \\quad \\forall c \\in \\R.\\] <p>Now, define</p> \\[\\Omega_{&gt;c} := \\qty{(x, t) \\in \\Omega \\mid U(x, t) &gt; c}\\] <p>and similarly for \\(\\Omega_{&lt;c}\\). Now, we can integrate the above inequality, split it into the two regions and use the divergence theorem for both regions. All the terms will cancel except for those at the shock curve:</p> \\[0 \\ge \\int_\\gamma \\qty(U^+ \\nu^t + f(U^+) \\nu^x) \\phi \\dd t + \\int_\\gamma \\qty(U^- \\nu^t + f(U^-) \\nu^x) \\phi \\dd t\\] <p>Now, this holds for all test functions \\(\\phi\\), so we get</p> \\[\\jump{q(U)} - s\\jump{U} \\le 0.\\] <p>We have</p> \\[ \\begin{aligned}     \\jump{\\eta(U)} &amp;= \\int_{U^-}^{U^+} \\eta'(v) \\dd v \\\\     &amp;= \\eval[\\nu'(v) (v-U^-)|_{U^-}^{U^+} - \\int_{U^-}^{U^+} \\nu''(v) (v-U^-) \\dd v \\\\     &amp;= \\eta' \\jump{U} - \\int_{U^-}^{U^+} \\nu''(v) (v-U^-) \\dd v. \\end{aligned} \\] <p>Similiarly, and with a few more steps, we get</p> \\[\\jump{q(U)} = \\eta'(U^+) \\jump{f(U)} - \\int_{U^-}^{U^+} \\nu''(v) (f(v) - f(U^-)) \\dd v.\\] <p>Now, we can use 2. and \\(\\eqref{eq:rankine_hugoniot}\\) to get</p> \\[ \\begin{aligned}     0 &amp; \\ge \\jump{q(U)} - s\\jump{U} \\\\     &amp; = \\eta'(U^+) \\Big(\\underbrace{\\jump{f(U)} - s\\jump{U}}_0\\Big) - \\int_{U^-}^{U^+} \\nu''(v) \\Big(s(v - U^-) - (f(v) - f(U^-))\\Big) \\dd v. \\end{aligned} \\] <p>Now, this must hold for all entrpy pairs \\((\\eta, q)\\), we end up with</p> \\[s \\le \\frac{f(v) - f(U^-)}{v - U^-} \\quad \\forall\\ v\\] <p>and similarly for the other inequality with \\(U^+\\).</p> <p>Follows by taking the limit \\(v \\to U^\\pm\\).</p>"},{"location":"theory/scalar_cons_laws/#stability-estimates","title":"Stability estimates","text":"<p>We can now integrate the entropy condition \\(\\eqref{eq:entropy_condition}\\) over space to get stability estimates on solutions. We get that the entropy decreases in time:</p> \\[0 \\ge \\int_\\R \\eta(U)_t + q(U)_x \\dd x = \\dv{t} \\int_\\R \\eta(U) \\dd x\\] <p>Thus, we get the bound</p> \\[\\int_\\R \\eta(U) \\dd x \\le \\int_\\R \\eta(U_0) \\dd x.\\] <p>Notably, for \\(\\eta(U) = \\abs{U}^p\\), we get \\(L^p\\) bounds</p> \\[\\norm{U(\\cdot, t)}_{L^p(\\R)} \\le \\norm{U_0}_{L^p(\\R)}.\\] <p>This holds for all \\(p \\ge 1\\), so taking the limit \\(p \\to \\infty\\), we get the maximum principle</p> \\[ \\begin{equation}     \\norm{U(\\cdot, t)}_{L^\\infty(\\R)} \\le \\norm{U_0}_{L^\\infty(\\R)} \\label{eq:max_principle} \\tag{MP} \\end{equation} \\] <p>We now have a bound on the amplitude, but we can also derive a bound on the derivate, i.e. the oscillations in \\(U\\).</p> <p>Definition (Total variation)</p> <p>Let \\(g\\) be defined on \\([a, b]\\). The total variation of \\(g\\) is defined as</p> \\[\\norm{g}_{TV([a,b])} = \\sup_{\\mathcal P} \\sum_{j=1}^{N-1} \\abs{g(x_{j+1}) - g(x_j)}\\] <p>For differentiable \\(g\\), this reduces to the \\(L^1\\) norm of the derivative:</p> \\[\\norm{g'}_{TV([a,b])} = \\int_a^b \\abs{\\dv{g}{x}} \\dd x.\\] <p>This is inly a seminorm (all constant functions have zero total variation). The bounded variation, however is a norm:</p> \\[\\norm{g}_{BV([a,b])} = \\norm{g}_{L^1([a,b])} + \\norm{g'}_{TV([a,b])}.\\] <p>The space of functions of bounded variation on \\(\\R\\) is</p> \\[BV(\\R) = \\qty{g \\in L^1(\\R) \\mid \\norm{g}_{BV(\\R)} &lt; \\infty}.\\] <p>Theorem</p> <p>Assume \\(f \\in C^1(\\R)\\) and \\(U_0 \\in L^1(\\R) \\cap L^\\infty(\\R)\\).</p> <p>Then, there exists a unique entropy soluiton of \\(\\eqref{eq:scalar_cons_law}\\) such that</p> <ol> <li> <p>\\(L^1\\)-bound:</p> \\[\\norm{U(\\cdot, t)}_{L^1(\\R)} \\le \\norm{U_0}_{L^1(\\R)}\\] </li> <li> <p>\\(L^\\infty\\)-bound:</p> \\[\\norm{U(\\cdot, t)}_{L^\\infty(\\R)} \\le \\norm{U_0}_{L^\\infty(\\R)}\\] </li> <li> <p>Total variation bound:</p> \\[U_0 \\in BV(\\R) \\implies \\norm{U(\\cdot, t)}_{TV(\\R)} \\le \\norm{U_0}_{TV(\\R)}\\] </li> <li> <p>Time continuity:</p> \\[U_0 \\in BV(\\R) \\implies \\norm{U(\\cdot, t) - U(\\cdot, s)}_{L^1(\\R)} \\le |t-s| M \\norm{U_0}_{TV(\\R)}\\] <ul> <li>\\(M = M(U_0) := \\max_{\\underline{u} \\le u \\le \\overline{u}} \\abs{f'(u)}\\)</li> <li>\\(\\displaystyle \\underline{u} = \\essinf_\\R U_0\\)</li> <li>\\(\\displaystyle \\overline{u} = \\esssup_\\R U_0\\).</li> </ul> </li> <li> <p>\\(L^1\\)-stability:</p> \\[\\norm{U(\\cdot, t) - V(\\cdot, t)}_{L^1(\\R)} \\le \\norm{U_0 - V_0}_{L^1(\\R)} \\quad \\forall t \\ge 0\\] </li> <li> <p>Local \\(L^1\\)-stability:</p> \\[\\int_a^b \\abs{U(x, t) - V(x, t)} \\dd x \\le \\int_{a-Mt}^{b+Mt} \\abs{U_0(x) - V_0(x)} \\dd x \\quad \\forall t \\ge 0, a &lt; b\\] <ul> <li>\\(M = \\max\\{M(U_0), M(V_0)\\}\\).</li> </ul> </li> <li> <p>Monotonicity: if we have \\(U_0 \\le V_0\\) almost everywhere in \\(\\R\\), then</p> </li> </ol> \\[U(\\cdot, t) \\le V(\\cdot, t) \\quad \\text{a.e. in } \\R\\] Proof ExistenceUniqueness1.2.3.4.5.6.7. <p>Let \\(U^\\eps\\) solve \\(\\eqref{eq:convection-diffusion})\\) and let \\(U = \\lim_{\\eps \\to 0} U^\\eps\\) be a limit. Then, we have seen that \\(U\\) satisfies the entropy condition \\(\\eqref{eq:entropy_condition}\\). Additionally, from the maximum principle \\(\\eqref{eq:max_principle}\\), we get that \\(U\\) is an entropy solution.</p> <p>Follows from 5. Set \\(V_0 = U_0\\). Then, we get that \\(U(\\cdot, t) = V(\\cdot, t)\\) almost everywhere in \\(\\R\\) for all \\(t \\ge 0\\).</p> <p>Follows from 5. by setting \\(V_0 = 0\\). Then, \\(V\\) must be zero.</p> <p>This is the maximum principle \\(\\eqref{eq:max_principle}\\).</p> <p>Follows from 5. by setting \\(V_0(x) = U_0(x+h)\\). Then, we have that</p> \\[\\int_\\R \\abs{U(x, t) - U(x+h, t)} \\dd x \\le \\int_\\R \\abs{U_0(x) - U_0(x+h)} \\dd x\\] <p>for all \\(h &gt; 0\\). Then, dividing by \\(h\\), and taking the limit \\(h \\to 0\\), we get the desired result.</p> <p>A discrete version of time continuity will be shown later for monotone finite volume schemes. The convergence of these to the entropy solution will then yield the result.</p> <p>Follows from 5. by taking the limit \\((a, b) \\to (-\\infty, \\infty)\\).</p> <p>Let \\(U, V\\) be two entropy solutions of \\(\\eqref{eq:scalar_cons_law}\\) with initial data \\(U_0, V_0\\). Then, it follows that</p> \\[ \\begin{aligned}     \\partial_t \\eta(U; c) + \\partial_x q(U; c) &amp;\\le 0 &amp;&amp; \\forall c \\in \\R \\\\     \\partial_t \\eta(d; V) + \\partial_x q(d; V) &amp;\\le 0 &amp;&amp; \\forall d \\in \\R. \\end{aligned} \\] <p>Thus, using the chain rule, we get</p> \\[ \\begin{aligned}     \\partial_t \\eta(U; V) &amp; = \\partial_t \\eval{\\eta(U; c)}_{c=V} + \\partial_t \\eval{\\eta(d; V)}_{d=U} \\\\     &amp; \\le - \\partial_x \\eval{q(U; c)}_{c=V} - \\partial_x \\eval{q(d; V)}_{d=U} \\\\     &amp; = - \\partial_x q(U; V) \\end{aligned} \\] <p>Equivalently,</p> \\[\\partial_t \\eta(U; V) + \\partial_x q(U; V) \\le 0.\\] <p>Now, integrating over the trapezoid</p> \\[\\{(x, t) : 0 \\le t \\le T, a - M(T-t) \\le x \\le b + M(T-t)\\}\\] <p>we get</p> \\[ \\begin{aligned}     0 \\le &amp; \\int_0^T \\int_{x_L(t)}^{x_R(t)} \\partial_t \\eta(U; V) + \\partial_x q(U; V) \\dd x \\dd t \\\\     =&amp; -\\int_{a-MT}^{b+MT} |U_0 - V_0| \\dd x + \\int_{a}^{b} |U(x, T) - V(x, T)| \\dd x \\\\     &amp; - \\int_0^T [q(U; V) - M\\eta(U; V)](x_L(t), t) \\dd t     - \\int_0^T [q(U; V) - M\\eta(U; V)](x_R(t), t) \\dd t \\end{aligned} \\] <p>Notice that \\(q(U; V) - M\\eta(U; V) = |U-V| \\qty(\\frac{q(U; V)}{|U-V|} - M) \\le 0\\), so we have</p> \\[\\int_{a}^{b} |U(x, T) - V(x, T)| \\dd x \\le \\int_{a-MT}^{b+MT} |U_0 - V_0| \\dd x.\\] <p>By \\(\\eqref{eq:scalar_cons_law}\\), we have the conservation</p> \\[\\int_\\R U(x, t) \\dd x = \\int_\\R U_0(x) \\dd x \\quad \\forall\\ t &gt; 0\\] <p>Therefore, we have that</p> \\[\\int_\\R (u - V)^+ \\dd x \\le \\int_\\R (U_0 - V_0)^+ \\dd x.\\] <p>Then, we can conclude with</p> \\[ \\begin{aligned}     U_0(x) &amp;\\le V_0(x) &amp; \\implies (U_0(x) - V_0(x))^+ = 0 \\\\     &amp; \\implies 0 \\le \\int_\\R (U - V)^+ \\dd x \\le 0 \\\\     &amp; \\implies U(\\cdot, t) \\le V(\\cdot, t) \\quad \\text{a.e. in } \\R. \\end{aligned} \\]"},{"location":"theory/scalar_cons_laws/#solutions-for-the-riemann-problem-for-general-f","title":"Solutions for the Riemann problem for general f","text":"<p>We can now use \\(\\eqref{eq:oleinik-E}\\) to solve the Riemann problem for general \\(f \\in C^1(\\R)\\) not necessarily convex. This condition is equivalent to </p> <p>The chord joining \\((U_L, f(U_L))\\) and \\((U_R, f (U_R))\\) must lie below the graph of the function \\(f\\) between these points when \\(U_L &lt; U_R\\). Similarly, it must lie above the graph when \\(U_L &gt; U_R\\).</p> <p>Assume without loss of generality that \\(U_L &lt; U_R\\). Let \\(f_c\\) be the lower convex envelope of \\(f\\):</p> \\[f_c(x):= \\sup_g \\qty{g(x) \\mid g \\text{ convex}, g \\le f}\\] <p>Now, the interval \\([U_L, U_R]\\) can be divided into two parts. One part is where \\(f_c = f\\), and the other is where \\(f_c &lt; f\\). In the second part, \\(f_c\\) is affine. We now use shocks in the affine region and rarefaction waves in the complement. Then, the solution is \\(\\eqref{eq:rarefaction_solution}\\) with \\(f\\) replaced by \\(f_c\\). For \\(U_L &gt; U_R\\), we instead use the upper convex envelope. Now, we often get rarefaction waves followed by shocks and vice versa. This is called a compound wave.</p>"},{"location":"theory/scalar_cons_laws/#summary","title":"Summary <sup>1</sup>","text":"<p>Solutions of the conservation law \\(\\eqref{eq:scalar_cons_law}\\) may develop discontinuities or shock waves, even for smooth initial data. Consequently, weak solutions are sought. Shock speeds are computed with the Rankine\u2013Hugoniot condition \\(\\eqref{eq:rankine_hugoniot}\\).</p> <ul> <li>Weak solutions are not necessarily unique. Entropy conditions like Oleinik\u2019s condition E \\(\\eqref{eq:oleinik-E}\\)  have to be imposed. Self-similar continuous solutions or rarefaction waves have to be considered.</li> <li>Explicit solutions for the Riemann problem (even for non-convex fluxes) can be constructed in terms of shocks, rarefaction waves and compound shocks.</li> <li>Entropy solutions exist, are unique and are stable in \\(L^1\\) with respect to the initial data. Furthermore, the entropy solutions satisfy an \\(L^\\infty\\) estimate, \\(L^p\\) estimates and are Total Variation Diminishing (TVD)\u2014that is, the total variation decreases in time.</li> </ul> <ol> <li> <p>https://www.uio.no/studier/emner/matnat/math/MAT-IN9240/h17/pensumliste/numcl_notes.pdf\u00a0\u21a9</p> </li> </ol>"}]}